{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animorphs Authorship Authenticity Analysis\n",
    "\n",
    "### Ethan Henley\n",
    "\n",
    "### Notebook 02: Word2Vec Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Loading](#Loading)\n",
    "- [W2V](#W2V)\n",
    "    - [Word Vector Model](#Word-Vector-Model)\n",
    "    - [Book and Chapter Vectorization](#Book-and-Chapter-Vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec as w2v\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean_no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, thats, first, name, obviously, cant, te...</td>\n",
       "      <td>[my, name, is, jake, thats, my, first, name, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A flying saucer?\" Marco said. He did laugh. T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[flying, saucer, qstinpunc, laugh, looked, cou...</td>\n",
       "      <td>[a, flying, saucer, qstinpunc, marco, said, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;They have come to destroy you.&gt;\\nIt was stran...</td>\n",
       "      <td>1</td>\n",
       "      <td>[anglepunc, come, destroy, anglepunc, strange,...</td>\n",
       "      <td>[anglepunc, they, have, come, to, destroy, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;Yeerks!&gt;\\nThe twin red lights slowed. They tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[anglepunc, yeerks, exclmpunc, anglepunc, twin...</td>\n",
       "      <td>[anglepunc, yeerks, exclmpunc, anglepunc, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hork-Bajir pointed his gun, or whatever it...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hork, odashpunc, bajir, pointed, gun, whateve...</td>\n",
       "      <td>[the, hork, odashpunc, bajir, pointed, his, gu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book  chapter                                               text  \\\n",
       "0     1        1  My name is Jake. That's my first name, obvious...   \n",
       "1     1        2  \"A flying saucer?\" Marco said. He did laugh. T...   \n",
       "2     1        3  <They have come to destroy you.>\\nIt was stran...   \n",
       "3     1        4  <Yeerks!>\\nThe twin red lights slowed. They tu...   \n",
       "4     1        5  The Hork-Bajir pointed his gun, or whatever it...   \n",
       "\n",
       "   authenticity                                              clean  \\\n",
       "0             1  [name, thats, first, name, obviously, cant, te...   \n",
       "1             1  [flying, saucer, qstinpunc, laugh, looked, cou...   \n",
       "2             1  [anglepunc, come, destroy, anglepunc, strange,...   \n",
       "3             1  [anglepunc, yeerks, exclmpunc, anglepunc, twin...   \n",
       "4             1  [hork, odashpunc, bajir, pointed, gun, whateve...   \n",
       "\n",
       "                                      clean_no_stops  \n",
       "0  [my, name, is, jake, thats, my, first, name, o...  \n",
       "1  [a, flying, saucer, qstinpunc, marco, said, he...  \n",
       "2  [anglepunc, they, have, come, to, destroy, you...  \n",
       "3  [anglepunc, yeerks, exclmpunc, anglepunc, the,...  \n",
       "4  [the, hork, odashpunc, bajir, pointed, his, gu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaps_df = pd.read_csv('../data/animorphs_chaps.csv')\n",
    "\n",
    "for col in ['clean','clean_no_stops']:\n",
    "    chaps_df[col] = chaps_df[col].map(literal_eval) # as lists\n",
    "    \n",
    "chaps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use transfer learning from the unsupervised word-embedding model Word2Vec to vectorize each book. Word2Vec primarily preserves content, so its use for stylometry here is novel and uncertain, but exploring its value is part of the purpose of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create or load a word vector model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize=300 # size of all w2v vectors\n",
    "\n",
    "def create_vectors(vector_file, col='clean', \n",
    "                   chaps_df=chaps_df, reset=False):\n",
    "    \"\"\"\n",
    "    A function to set up word vectorization for a given corpus,\n",
    "    or load it from a given file.\n",
    "    \"\"\"\n",
    "    try: # load word vectors\n",
    "        \n",
    "        assert not reset\n",
    "        \n",
    "        w2vmodel = w2v.load(vector_file)\n",
    "\n",
    "    except: # create word vectors\n",
    "\n",
    "        t0 = time.time() # this might be a while\n",
    "\n",
    "        # make corpus\n",
    "        corpus = list(chaps_df[col])\n",
    "\n",
    "        w2vmodel = w2v(corpus,\n",
    "                       size=vsize, # somewhat arbitrary, plecháč used 100 w\n",
    "                       # could gridsearch over most of these params, but\n",
    "                       # would take forever. instead, make informed decision\n",
    "                       window=5, \n",
    "                       min_count=2,\n",
    "                       sg=0, # continuous bag of words\n",
    "                       workers=3)\n",
    "        \n",
    "        w2vmodel.save(vector_file)   \n",
    "        \n",
    "        print('It took',time.time()-t0,'seconds to generate this model.')\n",
    "    \n",
    "    return w2vmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file = '../data/animorphs.vector'\n",
    "\n",
    "w2vmodel = create_vectors(vector_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common sense check on word similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earth', 0.9860408306121826),\n",
       " ('parasitic', 0.9683764576911926),\n",
       " ('invaded', 0.9607400894165039),\n",
       " ('destroyed', 0.9558642506599426),\n",
       " ('invasion', 0.9503868818283081),\n",
       " ('conquering', 0.9499269723892212),\n",
       " ('loser', 0.947063684463501),\n",
       " ('infested', 0.9470416903495789),\n",
       " ('kandrona', 0.9450056552886963),\n",
       " ('battle', 0.944513738155365)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.most_similar('planet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book and Chapter Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell was inextricably influenced by the work of Boom Devahastin Na Ayudhya, in the function `vectorize_corpus` available [here](https://github.com/boom-deva/FEMA-Power-Outage-Hotspot-Detection/blob/master/code/4_Preprocessing-and-NLP-Modeling.ipynb).\n",
    "\n",
    "Define a function to get the average vector of a list of words, ignoring unfamiliar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influenced by boom's vectorize_corpus\n",
    "def avg_vec_words(words, w2vmodel=w2vmodel):\n",
    "    \"\"\"\n",
    "    A function to get the average vector of a list of words.\n",
    "    Ignores unfamiliar words.\n",
    "    \"\"\"\n",
    "    vecs = [w2vmodel.wv.word_vec(w)    # vectorize word w\n",
    "            for w in words             # for all words\n",
    "            if w in w2vmodel.wv.vocab] # that are in the vocab\n",
    "    \n",
    "# # below code would treat unfamiliar words as 0 vectors instead of ignoring\n",
    "#     vecs = [w2vmodel.wv.word_vec(w)    # vectorize word w\n",
    "#             if w in w2vmodel.wv.vocab  # if w can be vectorized\n",
    "#             else np.zeros(vsize)       # otherwise give it a 0 vector\n",
    "#             for w in words]            # for all words\n",
    "    \n",
    "    return np.mean(vecs, axis=0) # return avg of vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>vec_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, thats, first, name, obviously, cant, te...</td>\n",
       "      <td>[my, name, is, jake, thats, my, first, name, o...</td>\n",
       "      <td>[0.050813198, 0.21546867, -0.11217794, 0.05301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A flying saucer?\" Marco said. He did laugh. T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[flying, saucer, qstinpunc, laugh, looked, cou...</td>\n",
       "      <td>[a, flying, saucer, qstinpunc, marco, said, he...</td>\n",
       "      <td>[0.0059409393, 0.23846294, -0.09167185, 0.0067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;They have come to destroy you.&gt;\\nIt was stran...</td>\n",
       "      <td>1</td>\n",
       "      <td>[anglepunc, come, destroy, anglepunc, strange,...</td>\n",
       "      <td>[anglepunc, they, have, come, to, destroy, you...</td>\n",
       "      <td>[0.00516426, 0.25513598, -0.040639274, -0.0519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;Yeerks!&gt;\\nThe twin red lights slowed. They tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[anglepunc, yeerks, exclmpunc, anglepunc, twin...</td>\n",
       "      <td>[anglepunc, yeerks, exclmpunc, anglepunc, the,...</td>\n",
       "      <td>[-0.027513022, 0.24088845, 0.00715725, -0.0299...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hork-Bajir pointed his gun, or whatever it...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hork, odashpunc, bajir, pointed, gun, whateve...</td>\n",
       "      <td>[the, hork, odashpunc, bajir, pointed, his, gu...</td>\n",
       "      <td>[-0.037028935, 0.29484826, 0.030976577, -0.076...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book  chapter                                               text  \\\n",
       "0     1        1  My name is Jake. That's my first name, obvious...   \n",
       "1     1        2  \"A flying saucer?\" Marco said. He did laugh. T...   \n",
       "2     1        3  <They have come to destroy you.>\\nIt was stran...   \n",
       "3     1        4  <Yeerks!>\\nThe twin red lights slowed. They tu...   \n",
       "4     1        5  The Hork-Bajir pointed his gun, or whatever it...   \n",
       "\n",
       "   authenticity                                              clean  \\\n",
       "0             1  [name, thats, first, name, obviously, cant, te...   \n",
       "1             1  [flying, saucer, qstinpunc, laugh, looked, cou...   \n",
       "2             1  [anglepunc, come, destroy, anglepunc, strange,...   \n",
       "3             1  [anglepunc, yeerks, exclmpunc, anglepunc, twin...   \n",
       "4             1  [hork, odashpunc, bajir, pointed, gun, whateve...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [my, name, is, jake, thats, my, first, name, o...   \n",
       "1  [a, flying, saucer, qstinpunc, marco, said, he...   \n",
       "2  [anglepunc, they, have, come, to, destroy, you...   \n",
       "3  [anglepunc, yeerks, exclmpunc, anglepunc, the,...   \n",
       "4  [the, hork, odashpunc, bajir, pointed, his, gu...   \n",
       "\n",
       "                                           vec_clean  \n",
       "0  [0.050813198, 0.21546867, -0.11217794, 0.05301...  \n",
       "1  [0.0059409393, 0.23846294, -0.09167185, 0.0067...  \n",
       "2  [0.00516426, 0.25513598, -0.040639274, -0.0519...  \n",
       "3  [-0.027513022, 0.24088845, 0.00715725, -0.0299...  \n",
       "4  [-0.037028935, 0.29484826, 0.030976577, -0.076...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaps_df['vec_clean'] = chaps_df['clean'].map(avg_vec_words)\n",
    "\n",
    "chaps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame of whole book vectorizations.\n",
    "\n",
    "`book_vec` is the simple averge vectorization of every word in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>book_vec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, thats, first, name, obviously, cant, te...</td>\n",
       "      <td>[0.0010895184, 0.2081184, -0.05931624, 0.01286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>My name is Rachel. I won't tell you my last na...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, tell, last, name, none, us, ever, tell,...</td>\n",
       "      <td>[-0.00226549, 0.22271992, -0.065148115, 0.0113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My name is Tobias. A freak of nature. One of a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, freak, nature, kind, tell, last, name, ...</td>\n",
       "      <td>[-0.0129256295, 0.21558568, -0.05230921, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My name is Cassie.\\nI can't tell you my last n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, cant, tell, last, name, wish, could, ca...</td>\n",
       "      <td>[-0.0025382496, 0.21817772, -0.069260634, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>My name is Marco.\\nI can't tell you my last na...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, cant, tell, last, name, live, believe, ...</td>\n",
       "      <td>[-0.00024333985, 0.22410813, -0.054545447, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book                                               text  authenticity  \\\n",
       "book                                                                          \n",
       "1        1  My name is Jake. That's my first name, obvious...             1   \n",
       "2        2  My name is Rachel. I won't tell you my last na...             1   \n",
       "3        3  My name is Tobias. A freak of nature. One of a...             1   \n",
       "4        4  My name is Cassie.\\nI can't tell you my last n...             1   \n",
       "5        5  My name is Marco.\\nI can't tell you my last na...             1   \n",
       "\n",
       "                                                  clean  \\\n",
       "book                                                      \n",
       "1     [name, thats, first, name, obviously, cant, te...   \n",
       "2     [name, tell, last, name, none, us, ever, tell,...   \n",
       "3     [name, freak, nature, kind, tell, last, name, ...   \n",
       "4     [name, cant, tell, last, name, wish, could, ca...   \n",
       "5     [name, cant, tell, last, name, live, believe, ...   \n",
       "\n",
       "                                               book_vec  \n",
       "book                                                     \n",
       "1     [0.0010895184, 0.2081184, -0.05931624, 0.01286...  \n",
       "2     [-0.00226549, 0.22271992, -0.065148115, 0.0113...  \n",
       "3     [-0.0129256295, 0.21558568, -0.05230921, 0.003...  \n",
       "4     [-0.0025382496, 0.21817772, -0.069260634, 0.00...  \n",
       "5     [-0.00024333985, 0.22410813, -0.054545447, 0.0...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_gb = chaps_df.groupby(by='book')\n",
    "\n",
    "books_df = pd.DataFrame(data={\n",
    "    'book':books_gb['book'].mean(), # book number\n",
    "    # newline-joined chapter texts make up book text\n",
    "    'text':['\\n\\n\\n'.join([c\n",
    "                           for i,c in enumerate(\n",
    "                               chaps_df.loc[chaps_df['book']==b,'text'])]\n",
    "                         ) for b in chaps_df['book'].unique()],\n",
    "    'authenticity':books_gb['authenticity'].mean(), # authenticity\n",
    "    'clean':[[w \n",
    "              for c in chaps_df.loc[chaps_df['book']==b, 'clean'] \n",
    "              for w in c] for b in chaps_df['book'].unique()], # clean text\n",
    "    'book_vec':[avg_vec_words(\n",
    "        [w \n",
    "         for c in chaps_df.loc[chaps_df['book']==b, 'clean'] \n",
    "         for w in c]) for b in chaps_df['book'].unique()] # book vector\n",
    "})\n",
    "\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the way `pandas` and `.csv` files interact and store non-native datatypes, we need to save our array columns in an odd way and then undo the transformation when we load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save np arrays as lists for convenient csv use\n",
    "chaps_df['vec_clean'] = chaps_df['vec_clean'].map(list)\n",
    "books_df['book_vec'] = books_df['book_vec'].map(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save updated DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaps_df.to_csv('../data/animorphs_chaps.csv', index=False)\n",
    "books_df.to_csv('../data/animorphs_books.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used Word2Vec to vectorize our chapters and books, but whether or not it is useful for stylometry can only be known after supervised modeling. We move onward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Continue to next notebook.](./03_svm_on_w2v.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
