{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec as w2v\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>vec_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, thats, first, name, obviously, cant, te...</td>\n",
       "      <td>[my, name, is, jake, thats, my, first, name, o...</td>\n",
       "      <td>[-0.06084491 -0.07821839  0.1802005  -0.032568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A flying saucer?\" Marco said. He did laugh. T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[flying, saucer, laugh, looked, could, feel, h...</td>\n",
       "      <td>[a, flying, saucer, marco, said, he, did, laug...</td>\n",
       "      <td>[-0.07276286 -0.0811749   0.17935286 -0.038883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;They have come to destroy you.&gt;\\nIt was stran...</td>\n",
       "      <td>1</td>\n",
       "      <td>[come, destroy, strange, way, knew, telling, t...</td>\n",
       "      <td>[they, have, come, to, destroy, you, it, was, ...</td>\n",
       "      <td>[-1.03591643e-01 -9.50562879e-02  1.48249313e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;Yeerks!&gt;\\nThe twin red lights slowed. They tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[yeerks, twin, red, lights, slowed, turned, ci...</td>\n",
       "      <td>[yeerks, the, twin, red, lights, slowed, they,...</td>\n",
       "      <td>[-1.19802251e-01 -1.08502194e-01  1.65713996e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hork-Bajir pointed his gun, or whatever it...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hork, bajir, pointed, gun, whatever, around, ...</td>\n",
       "      <td>[the, hork, bajir, pointed, his, gun, or, what...</td>\n",
       "      <td>[-1.01123430e-01 -1.02614835e-01  1.57715589e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book  chapter                                               text  \\\n",
       "0     1        1  My name is Jake. That's my first name, obvious...   \n",
       "1     1        2  \"A flying saucer?\" Marco said. He did laugh. T...   \n",
       "2     1        3  <They have come to destroy you.>\\nIt was stran...   \n",
       "3     1        4  <Yeerks!>\\nThe twin red lights slowed. They tu...   \n",
       "4     1        5  The Hork-Bajir pointed his gun, or whatever it...   \n",
       "\n",
       "   authenticity                                              clean  \\\n",
       "0             1  [name, thats, first, name, obviously, cant, te...   \n",
       "1             1  [flying, saucer, laugh, looked, could, feel, h...   \n",
       "2             1  [come, destroy, strange, way, knew, telling, t...   \n",
       "3             1  [yeerks, twin, red, lights, slowed, turned, ci...   \n",
       "4             1  [hork, bajir, pointed, gun, whatever, around, ...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [my, name, is, jake, thats, my, first, name, o...   \n",
       "1  [a, flying, saucer, marco, said, he, did, laug...   \n",
       "2  [they, have, come, to, destroy, you, it, was, ...   \n",
       "3  [yeerks, the, twin, red, lights, slowed, they,...   \n",
       "4  [the, hork, bajir, pointed, his, gun, or, what...   \n",
       "\n",
       "                                           vec_clean  \n",
       "0  [-0.06084491 -0.07821839  0.1802005  -0.032568...  \n",
       "1  [-0.07276286 -0.0811749   0.17935286 -0.038883...  \n",
       "2  [-1.03591643e-01 -9.50562879e-02  1.48249313e-...  \n",
       "3  [-1.19802251e-01 -1.08502194e-01  1.65713996e-...  \n",
       "4  [-1.01123430e-01 -1.02614835e-01  1.57715589e-...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaps_df = pd.read_csv('../data/animorphs_chaps.csv')\n",
    "\n",
    "for col in ['clean','clean_no_stops']:\n",
    "    chaps_df[col] = chaps_df[col].map(literal_eval) # as lists\n",
    "    \n",
    "chaps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create or load a word vector model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize=300 # size of all w2v vectors\n",
    "\n",
    "def create_vectors(vector_file, col='clean', \n",
    "                   chaps_df=chaps_df, reset=False):\n",
    "    \"\"\"\n",
    "    A function to set up word vectorization for a given corpus,\n",
    "    or load it from a given file.\n",
    "    \"\"\"\n",
    "    try: # load word vectors\n",
    "        \n",
    "        assert not reset\n",
    "        \n",
    "        w2vmodel = w2v.load(vector_file)\n",
    "\n",
    "    except: # create word vectors\n",
    "\n",
    "        t0 = time.time() # this might be a while\n",
    "\n",
    "        # make corpus\n",
    "        corpus = list(chaps_df[col])\n",
    "\n",
    "        w2vmodel = w2v(corpus,\n",
    "                       size=vsize, # somewhat arbitrary, plecháč used 100 d\n",
    "                       # could gridsearch over most of these params, but\n",
    "                       # would take forever. instead, make informed decision\n",
    "                       window=5, \n",
    "                       min_count=2,\n",
    "                       sg=1, # skipgram\n",
    "                       workers=3)\n",
    "        \n",
    "        w2vmodel.save(vector_file)   \n",
    "        \n",
    "        print('It took',time.time()-t0,'seconds to generate this model.')\n",
    "    \n",
    "    return w2vmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file = '../data/animorphs.vector'\n",
    "\n",
    "w2vmodel = create_vectors(vector_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('invaded', 0.8538174629211426),\n",
       " ('invading', 0.843326210975647),\n",
       " ('leera', 0.8390116691589355),\n",
       " ('universe', 0.8216259479522705),\n",
       " ('planets', 0.8168292045593262),\n",
       " ('galaxy', 0.8142693042755127),\n",
       " ('earth', 0.812616765499115),\n",
       " ('conquest', 0.8082102537155151),\n",
       " ('resistance', 0.8065967559814453),\n",
       " ('throughout', 0.805733323097229)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.most_similar('planet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([w2vmodel.wv.word_vec('planet'), w2vmodel.wv.word_vec('earth')], axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell was inextricably influenced by the work of Boom Devahastin Na Ayudhya, in the function `vectorize_corpus` available [here](https://github.com/boom-deva/FEMA-Power-Outage-Hotspot-Detection/blob/master/code/4_Preprocessing-and-NLP-Modeling.ipynb).\n",
    "\n",
    "Define a function to get the average vector of a list of words, ignoring unfamiliar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influenced by boom's vectorize_corpus\n",
    "def avg_vec_words(words, w2vmodel=w2vmodel):\n",
    "    \"\"\"\n",
    "    A function to get the average vector of a list of words.\n",
    "    Ignores unfamiliar words.\n",
    "    \"\"\"\n",
    "    vecs = [w2vmodel.wv.word_vec(w)    # vectorize word w\n",
    "            for w in words             # for all words\n",
    "            if w in w2vmodel.wv.vocab] # that are in the vocab\n",
    "    \n",
    "# below code would treat unfamiliar words as 0 vectors instead of ignoring\n",
    "#     vecs = [w2vmodel.wv.word_vec(w)    # vectorize word w\n",
    "#             if w in w2vmodel.wv.vocab  # if w can be vectorized\n",
    "#             else np.zeros(vsize)       # otherwise give it a 0 vector\n",
    "#             for w in words]            # for all words\n",
    "    \n",
    "    return np.mean(vecs, axis=0) # return avg of vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>vec_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, thats, first, name, obviously, cant, te...</td>\n",
       "      <td>[my, name, is, jake, thats, my, first, name, o...</td>\n",
       "      <td>[-0.06084491, -0.07821839, 0.1802005, -0.03256...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A flying saucer?\" Marco said. He did laugh. T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[flying, saucer, laugh, looked, could, feel, h...</td>\n",
       "      <td>[a, flying, saucer, marco, said, he, did, laug...</td>\n",
       "      <td>[-0.07276286, -0.081174895, 0.17935286, -0.038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;They have come to destroy you.&gt;\\nIt was stran...</td>\n",
       "      <td>1</td>\n",
       "      <td>[come, destroy, strange, way, knew, telling, t...</td>\n",
       "      <td>[they, have, come, to, destroy, you, it, was, ...</td>\n",
       "      <td>[-0.10359164, -0.09505629, 0.14824931, -0.0206...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;Yeerks!&gt;\\nThe twin red lights slowed. They tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[yeerks, twin, red, lights, slowed, turned, ci...</td>\n",
       "      <td>[yeerks, the, twin, red, lights, slowed, they,...</td>\n",
       "      <td>[-0.11980225, -0.108502194, 0.165714, -0.03714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hork-Bajir pointed his gun, or whatever it...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hork, bajir, pointed, gun, whatever, around, ...</td>\n",
       "      <td>[the, hork, bajir, pointed, his, gun, or, what...</td>\n",
       "      <td>[-0.10112343, -0.102614835, 0.15771559, -0.031...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book  chapter                                               text  \\\n",
       "0     1        1  My name is Jake. That's my first name, obvious...   \n",
       "1     1        2  \"A flying saucer?\" Marco said. He did laugh. T...   \n",
       "2     1        3  <They have come to destroy you.>\\nIt was stran...   \n",
       "3     1        4  <Yeerks!>\\nThe twin red lights slowed. They tu...   \n",
       "4     1        5  The Hork-Bajir pointed his gun, or whatever it...   \n",
       "\n",
       "   authenticity                                              clean  \\\n",
       "0             1  [name, thats, first, name, obviously, cant, te...   \n",
       "1             1  [flying, saucer, laugh, looked, could, feel, h...   \n",
       "2             1  [come, destroy, strange, way, knew, telling, t...   \n",
       "3             1  [yeerks, twin, red, lights, slowed, turned, ci...   \n",
       "4             1  [hork, bajir, pointed, gun, whatever, around, ...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [my, name, is, jake, thats, my, first, name, o...   \n",
       "1  [a, flying, saucer, marco, said, he, did, laug...   \n",
       "2  [they, have, come, to, destroy, you, it, was, ...   \n",
       "3  [yeerks, the, twin, red, lights, slowed, they,...   \n",
       "4  [the, hork, bajir, pointed, his, gun, or, what...   \n",
       "\n",
       "                                           vec_clean  \n",
       "0  [-0.06084491, -0.07821839, 0.1802005, -0.03256...  \n",
       "1  [-0.07276286, -0.081174895, 0.17935286, -0.038...  \n",
       "2  [-0.10359164, -0.09505629, 0.14824931, -0.0206...  \n",
       "3  [-0.11980225, -0.108502194, 0.165714, -0.03714...  \n",
       "4  [-0.10112343, -0.102614835, 0.15771559, -0.031...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaps_df['vec_clean'] = chaps_df['clean'].map(avg_vec_words)\n",
    "\n",
    "chaps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame of two potential vectorizations of books.\n",
    "\n",
    "`book_vec` is the simple averge vectorization of every word in the book.\n",
    "`avg_chap_vec` is the average of the vectorization of each chapter (which is itself the average vectorization of every word in the chapter), which would be inappropriate for normal use but might be relevant in chapter-based classification methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_gb = chaps_df.groupby(by='book')\n",
    "\n",
    "books_df = pd.DataFrame(data={\n",
    "    'book':books_gb['book'].mean(), # book number\n",
    "    'book_vec':[avg_vec_words(\n",
    "        [w \n",
    "         for c in chaps_df.loc[chaps_df['book']==b, 'clean'] \n",
    "         for w in c]) for b in chaps_df['book'].unique()], # book vector\n",
    "    'avg_chap_vec':books_gb['vec_clean'].apply(\n",
    "        lambda v: np.mean(v, axis=0)), # avg vector of chapters in book\n",
    "    'authenticity':books_gb['authenticity'].mean() # authenticity\n",
    "})\n",
    "\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save updated DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaps_df.to_csv('../data/animorphs_chaps.csv', index=False)\n",
    "books_df.to_csv('../data/animorphs_books.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
