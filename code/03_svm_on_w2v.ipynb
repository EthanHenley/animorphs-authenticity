{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animorphs Authorship Authenticity Analysis\n",
    "\n",
    "### Ethan Henley\n",
    "\n",
    "### Notebook 03: Support Vector Machine on Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Supervised Modeling Process\n",
    "\n",
    "Our problem was structured in a way such that we could not do an ordinary train/test split; ideally, our model makes a prediction on a single Animorphs book of unknown authorship, trained on all the other books in the series. In order to simulate this for validation, we adapted the strategy of leave-one-out cross validation, which generates seperate models each trained on all but one data point and then assesses the scores for each individual result to help determine the worthwhileness of a model. This is typically very expensive, but made sense for our dataset of only 54 book-level datapoints. We extrapolated this to leave-one-book-out cross validation for modeling based on chapter, as a model that requires other chapters from the same book to have known authorship to predict authorship of a single chapter would not fit our intended use case.\n",
    "\n",
    "Ultimately, we determined that the results of the Word2Vec-based transfer learning process were likely not useful for stylometry or authorship analysisâ€”they were more likely swayed by variation in content than in style across the texts, as visible in linearly sequential shifting predicted authenticity probabilities across the first 24 all-authentic books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Loading](#Loading)\n",
    "- [Modeling](#Modeling)\n",
    "- [Model Evaluation](#Model-Evaluation)\n",
    "- [Midway Reassessment](#Midway-Reassessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# a small module of functions i wrote for this project:\n",
    "from small_lib import inacc_set, col_acc, do_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `chaps_df` and undo array-to-list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean_no_stops</th>\n",
       "      <th>vec_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>[name, thats, first, name, obviously, cant, te...</td>\n",
       "      <td>[my, name, is, jake, thats, my, first, name, o...</td>\n",
       "      <td>[0.050813198, 0.21546867, -0.11217794, 0.05301...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A flying saucer?\" Marco said. He did laugh. T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[flying, saucer, qstinpunc, laugh, looked, cou...</td>\n",
       "      <td>[a, flying, saucer, qstinpunc, marco, said, he...</td>\n",
       "      <td>[0.0059409393, 0.23846294, -0.09167185, 0.0067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;They have come to destroy you.&gt;\\nIt was stran...</td>\n",
       "      <td>1</td>\n",
       "      <td>[anglepunc, come, destroy, anglepunc, strange,...</td>\n",
       "      <td>[anglepunc, they, have, come, to, destroy, you...</td>\n",
       "      <td>[0.00516426, 0.25513598, -0.040639274, -0.0519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;Yeerks!&gt;\\nThe twin red lights slowed. They tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[anglepunc, yeerks, exclmpunc, anglepunc, twin...</td>\n",
       "      <td>[anglepunc, yeerks, exclmpunc, anglepunc, the,...</td>\n",
       "      <td>[-0.027513022, 0.24088845, 0.00715725, -0.0299...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hork-Bajir pointed his gun, or whatever it...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hork, odashpunc, bajir, pointed, gun, whateve...</td>\n",
       "      <td>[the, hork, odashpunc, bajir, pointed, his, gu...</td>\n",
       "      <td>[-0.037028935, 0.29484826, 0.030976577, -0.076...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book  chapter                                               text  \\\n",
       "0     1        1  My name is Jake. That's my first name, obvious...   \n",
       "1     1        2  \"A flying saucer?\" Marco said. He did laugh. T...   \n",
       "2     1        3  <They have come to destroy you.>\\nIt was stran...   \n",
       "3     1        4  <Yeerks!>\\nThe twin red lights slowed. They tu...   \n",
       "4     1        5  The Hork-Bajir pointed his gun, or whatever it...   \n",
       "\n",
       "   authenticity                                              clean  \\\n",
       "0             1  [name, thats, first, name, obviously, cant, te...   \n",
       "1             1  [flying, saucer, qstinpunc, laugh, looked, cou...   \n",
       "2             1  [anglepunc, come, destroy, anglepunc, strange,...   \n",
       "3             1  [anglepunc, yeerks, exclmpunc, anglepunc, twin...   \n",
       "4             1  [hork, odashpunc, bajir, pointed, gun, whateve...   \n",
       "\n",
       "                                      clean_no_stops  \\\n",
       "0  [my, name, is, jake, thats, my, first, name, o...   \n",
       "1  [a, flying, saucer, qstinpunc, marco, said, he...   \n",
       "2  [anglepunc, they, have, come, to, destroy, you...   \n",
       "3  [anglepunc, yeerks, exclmpunc, anglepunc, the,...   \n",
       "4  [the, hork, odashpunc, bajir, pointed, his, gu...   \n",
       "\n",
       "                                           vec_clean  \n",
       "0  [0.050813198, 0.21546867, -0.11217794, 0.05301...  \n",
       "1  [0.0059409393, 0.23846294, -0.09167185, 0.0067...  \n",
       "2  [0.00516426, 0.25513598, -0.040639274, -0.0519...  \n",
       "3  [-0.027513022, 0.24088845, 0.00715725, -0.0299...  \n",
       "4  [-0.037028935, 0.29484826, 0.030976577, -0.076...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaps_df = pd.read_csv('../data/animorphs_chaps.csv')\n",
    "\n",
    "for col in ['clean','clean_no_stops', 'vec_clean']:\n",
    "    chaps_df[col] = chaps_df[col].map(literal_eval) # as lists\n",
    "    \n",
    "for col in ['vec_clean']:\n",
    "    chaps_df[col] = chaps_df[col].map(np.array) # as array\n",
    "    \n",
    "chaps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `books_df` and undo array-to-list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>text</th>\n",
       "      <th>authenticity</th>\n",
       "      <th>clean</th>\n",
       "      <th>book_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My name is Jake. That's my first name, obvious...</td>\n",
       "      <td>1</td>\n",
       "      <td>['name', 'thats', 'first', 'name', 'obviously'...</td>\n",
       "      <td>[0.0010895184, 0.2081184, -0.05931624, 0.01286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>My name is Rachel. I won't tell you my last na...</td>\n",
       "      <td>1</td>\n",
       "      <td>['name', 'tell', 'last', 'name', 'none', 'us',...</td>\n",
       "      <td>[-0.00226549, 0.22271992, -0.065148115, 0.0113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>My name is Tobias. A freak of nature. One of a...</td>\n",
       "      <td>1</td>\n",
       "      <td>['name', 'freak', 'nature', 'kind', 'tell', 'l...</td>\n",
       "      <td>[-0.0129256295, 0.21558568, -0.05230921, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>My name is Cassie.\\nI can't tell you my last n...</td>\n",
       "      <td>1</td>\n",
       "      <td>['name', 'cant', 'tell', 'last', 'name', 'wish...</td>\n",
       "      <td>[-0.0025382496, 0.21817772, -0.069260634, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My name is Marco.\\nI can't tell you my last na...</td>\n",
       "      <td>1</td>\n",
       "      <td>['name', 'cant', 'tell', 'last', 'name', 'live...</td>\n",
       "      <td>[-0.00024333985, 0.22410813, -0.054545447, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book                                               text  authenticity  \\\n",
       "0     1  My name is Jake. That's my first name, obvious...             1   \n",
       "1     2  My name is Rachel. I won't tell you my last na...             1   \n",
       "2     3  My name is Tobias. A freak of nature. One of a...             1   \n",
       "3     4  My name is Cassie.\\nI can't tell you my last n...             1   \n",
       "4     5  My name is Marco.\\nI can't tell you my last na...             1   \n",
       "\n",
       "                                               clean  \\\n",
       "0  ['name', 'thats', 'first', 'name', 'obviously'...   \n",
       "1  ['name', 'tell', 'last', 'name', 'none', 'us',...   \n",
       "2  ['name', 'freak', 'nature', 'kind', 'tell', 'l...   \n",
       "3  ['name', 'cant', 'tell', 'last', 'name', 'wish...   \n",
       "4  ['name', 'cant', 'tell', 'last', 'name', 'live...   \n",
       "\n",
       "                                            book_vec  \n",
       "0  [0.0010895184, 0.2081184, -0.05931624, 0.01286...  \n",
       "1  [-0.00226549, 0.22271992, -0.065148115, 0.0113...  \n",
       "2  [-0.0129256295, 0.21558568, -0.05230921, 0.003...  \n",
       "3  [-0.0025382496, 0.21817772, -0.069260634, 0.00...  \n",
       "4  [-0.00024333985, 0.22410813, -0.054545447, 0.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv('../data/animorphs_books.csv')\n",
    "\n",
    "for col in ['book_vec']:\n",
    "    books_df[col] = books_df[col].map(literal_eval) # as lists\n",
    "    \n",
    "for col in ['book_vec']:\n",
    "    books_df[col] = books_df[col].map(np.array) # as array\n",
    "    \n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1007\n",
    "cv_times = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a manually-written, not-cross-validated gridsearch `do_gs` available in the local module. This is desirable because of our leave-one-out training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results using leave-one-out trainingâ€”each book's results are generated by a model trained on all other books. We have two different functions to get these results: one operates on books as wholes, the other averages chapters of specific books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_one_out_b(book_out, model, params, books_df=books_df):\n",
    "\n",
    "    train_inds = books_df['book'] != book_out\n",
    "    test_inds = books_df['book'] == book_out\n",
    "    \n",
    "    X_b = pd.DataFrame(list(books_df['book_vec'])).loc[train_inds]\n",
    "    y_b = books_df['authenticity'].loc[train_inds]\n",
    "    \n",
    "    X_b_test = pd.DataFrame(list(books_df['book_vec'])).loc[test_inds]\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_b = ss.fit_transform(X_b)\n",
    "    X_b_test = ss.transform(X_b_test)\n",
    "\n",
    "    model = do_gs(model, params, X_b, y_b)\n",
    "    return (model.predict_proba(X_b_test)[:,1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_one_out_c(book_out, model, params, chaps_df=chaps_df):\n",
    "\n",
    "    train_inds = chaps_df['book'] != book_out\n",
    "    test_inds = chaps_df['book'] == book_out\n",
    "    \n",
    "    X_c = pd.DataFrame(list(chaps_df['vec_clean'])).loc[train_inds]\n",
    "    y_c = chaps_df['authenticity'].loc[train_inds]\n",
    "    \n",
    "    X_c_test = pd.DataFrame(list(chaps_df['vec_clean'])).loc[test_inds]\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_c = ss.fit_transform(X_c)\n",
    "    X_c_test = ss.transform(X_c_test)\n",
    "\n",
    "    model = do_gs(model, params, X_c, y_c)\n",
    "    return (np.mean(model.predict(X_c_test)), \n",
    "            np.mean(model.predict_proba(X_c_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Support Vector Machine classifier, combined with our leave-one-out gridsearch, to independently generate predictions of authenticity for each individual book, using the data of all the other books in the corpus. This leave-one-out method allows us to maximize the training data, which is useful in this dataset where individual data points carry major unique characteristics and our overall $n$ is small.\n",
    "\n",
    "We generate prediction results for each book in three ways: the probability of a book being authentic, and the average chapter prediction and chapter probability of authenticity based on the corpus of other books' chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'C':np.logspace(2,4,5),\n",
    "    'kernel':['rbf']\n",
    "}\n",
    "svm = SVC(random_state=seed, gamma='scale',\n",
    "          max_iter=5e4, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'book':range(1,55)})\n",
    "results['w2vsvm book pred proba'] = results['book'].map(\n",
    "    lambda b:pred_one_out_b(b, svm, svm_params))\n",
    "temp_c = results['book'].map(lambda b:pred_one_out_c(b, svm, svm_params))\n",
    "results['w2vsvm chap pred avg'] = temp_c.map(lambda p:p[0])\n",
    "results['w2vsvm chap pred proba avg'] = temp_c.map(lambda p:p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['authenticity'] = books_df['authenticity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../data/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w2vsvm chap pred avg': 0.8703703703703703,\n",
       " 'w2vsvm chap pred proba avg': 0.8703703703703703,\n",
       " 'w2vsvm book pred proba': 0.8518518518518519}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "{col:col_acc(results, col) \n",
    " for col in ['w2vsvm chap pred avg',\n",
    "             'w2vsvm chap pred proba avg',\n",
    "             'w2vsvm book pred proba']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these model types result in accuracy higher than 90%; this is troubling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will inspect which books each individual prediction variety failed to predict properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>w2vsvm book pred proba</th>\n",
       "      <th>w2vsvm chap pred avg</th>\n",
       "      <th>w2vsvm chap pred proba avg</th>\n",
       "      <th>authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991171</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.740572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.972882</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.729202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.978186</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.973608</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.730618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.988004</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.796461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.908672</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.753434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.968291</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.693666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.802080</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.713113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.970244</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.745037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.989242</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.743199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.991739</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.877033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.633117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.607864</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.634267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.619457</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.599833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.926758</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.667490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.812878</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.626720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.703152</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.603253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816811</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.611624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.965214</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.720279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.870030</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.597789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.886196</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.703048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.782183</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.575678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.915102</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.530443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.193768</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.623928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.921148</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.622850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.279394</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.539958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.448081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.092693</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.502158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.439558</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.476123</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.472304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.151493</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.341967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.935169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.526418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.340789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.593449</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.653802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.454811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.374758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.292223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.308420</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.430910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0.194139</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.461516</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.073931</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.334334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.123939</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.187455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.439934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0.233575</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.395414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>0.211905</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.259704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>0.094021</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.321971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.114641</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.195546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.209518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.458247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.233238</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.305486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0.704774</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.519665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.185920</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.203767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.441318</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.374748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.239383</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.453208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.462505</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.343767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book  w2vsvm book pred proba  w2vsvm chap pred avg  \\\n",
       "0      1                0.991171              0.925926   \n",
       "1      2                0.972882              0.869565   \n",
       "2      3                0.978186              0.777778   \n",
       "3      4                0.973608              0.920000   \n",
       "4      5                0.988004              0.875000   \n",
       "5      6                0.908672              0.840000   \n",
       "6      7                0.968291              0.740741   \n",
       "7      8                0.802080              0.863636   \n",
       "8      9                0.970244              0.958333   \n",
       "9     10                0.989242              0.923077   \n",
       "10    11                0.991739              0.869565   \n",
       "11    12                0.877033              0.629630   \n",
       "12    13                0.607864              0.629630   \n",
       "13    14                0.619457              0.666667   \n",
       "14    15                0.926758              0.777778   \n",
       "15    16                0.812878              0.653846   \n",
       "16    17                0.703152              0.633333   \n",
       "17    18                0.816811              0.758621   \n",
       "18    19                0.965214              0.821429   \n",
       "19    20                0.870030              0.692308   \n",
       "20    21                0.886196              0.857143   \n",
       "21    22                0.782183              0.586207   \n",
       "22    23                0.915102              0.516129   \n",
       "23    24                0.193768              0.666667   \n",
       "24    25                0.921148              0.592593   \n",
       "25    26                0.279394              0.464286   \n",
       "26    27                0.024519              0.357143   \n",
       "27    28                0.092693              0.444444   \n",
       "28    29                0.439558              0.642857   \n",
       "29    30                0.476123              0.433333   \n",
       "30    31                0.151493              0.259259   \n",
       "31    32                0.935169              0.500000   \n",
       "32    33                0.150482              0.185185   \n",
       "33    34                0.593449              0.800000   \n",
       "34    35                0.235365              0.440000   \n",
       "35    36                0.118263              0.166667   \n",
       "36    37                0.014957              0.090909   \n",
       "37    38                0.308420              0.428571   \n",
       "38    39                0.194139              0.409091   \n",
       "39    40                0.073931              0.125000   \n",
       "40    41                0.123939              0.107143   \n",
       "41    42                0.025351              0.480000   \n",
       "42    43                0.233575              0.125000   \n",
       "43    44                0.211905              0.125000   \n",
       "44    45                0.094021              0.217391   \n",
       "45    46                0.114641              0.086957   \n",
       "46    47                0.170892              0.076923   \n",
       "47    48                0.509604              0.400000   \n",
       "48    49                0.233238              0.166667   \n",
       "49    50                0.704774              0.500000   \n",
       "50    51                0.185920              0.038462   \n",
       "51    52                0.441318              0.310345   \n",
       "52    53                0.239383              0.478261   \n",
       "53    54                0.462505              0.227273   \n",
       "\n",
       "    w2vsvm chap pred proba avg  authenticity  \n",
       "0                     0.740572             1  \n",
       "1                     0.729202             1  \n",
       "2                     0.720986             1  \n",
       "3                     0.730618             1  \n",
       "4                     0.796461             1  \n",
       "5                     0.753434             1  \n",
       "6                     0.693666             1  \n",
       "7                     0.713113             1  \n",
       "8                     0.745037             1  \n",
       "9                     0.743199             1  \n",
       "10                    0.734757             1  \n",
       "11                    0.633117             1  \n",
       "12                    0.634267             1  \n",
       "13                    0.599833             1  \n",
       "14                    0.667490             1  \n",
       "15                    0.626720             1  \n",
       "16                    0.603253             1  \n",
       "17                    0.611624             1  \n",
       "18                    0.720279             1  \n",
       "19                    0.597789             1  \n",
       "20                    0.703048             1  \n",
       "21                    0.575678             1  \n",
       "22                    0.530443             1  \n",
       "23                    0.623928             1  \n",
       "24                    0.622850             0  \n",
       "25                    0.539958             1  \n",
       "26                    0.448081             0  \n",
       "27                    0.502158             0  \n",
       "28                    0.569930             0  \n",
       "29                    0.472304             0  \n",
       "30                    0.341967             0  \n",
       "31                    0.526418             1  \n",
       "32                    0.340789             0  \n",
       "33                    0.653802             0  \n",
       "34                    0.454811             0  \n",
       "35                    0.374758             0  \n",
       "36                    0.292223             0  \n",
       "37                    0.430910             0  \n",
       "38                    0.461516             0  \n",
       "39                    0.334334             0  \n",
       "40                    0.187455             0  \n",
       "41                    0.439934             0  \n",
       "42                    0.395414             0  \n",
       "43                    0.259704             0  \n",
       "44                    0.321971             0  \n",
       "45                    0.195546             0  \n",
       "46                    0.209518             0  \n",
       "47                    0.458247             0  \n",
       "48                    0.305486             0  \n",
       "49                    0.519665             0  \n",
       "50                    0.203767             0  \n",
       "51                    0.374748             0  \n",
       "52                    0.453208             1  \n",
       "53                    0.343767             1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which books did each method get wrong?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w2vsvm chap pred avg': {25, 26, 29, 34, 50, 53, 54},\n",
       " 'w2vsvm chap pred proba avg': {25, 28, 29, 34, 50, 53, 54},\n",
       " 'w2vsvm book pred proba': {24, 25, 26, 34, 48, 50, 53, 54}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Which books did each method get wrong?')\n",
    "{col:inacc_set(results, col) \n",
    " for col in ['w2vsvm chap pred avg',\n",
    "             'w2vsvm chap pred proba avg',\n",
    "             'w2vsvm book pred proba']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkably, each type makes at least one unique mistake, and none of them can accurately predict all of the *interesting* booksâ€”that is, the books whose authenticity might seem out of place in order; 25, 26, 32, 53, and 54. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 25, 26, 28, 29, 34, 48, 50, 53, 54]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bads = sorted(list(inacc_set(results, 'w2vsvm book pred proba') |\n",
    "                   inacc_set(results, 'w2vsvm chap pred proba avg') |\n",
    "                   inacc_set(results, 'w2vsvm chap pred avg')))\n",
    "bads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below, blue, red, and pink dots will represent the three different methods of determining authenticity probability; black bars will represent the true authenticity of each book, and lime bars will represent the true authenticity of books which at least one of the methods assesses incorrectly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAEWCAYAAACjVwf7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXwU9f348dc7AZQzoHhwCZEilJADCEoAIYgcFUS0KF4ItIpnPVq1HqUefFtstdWq9fpWRS0WtVak1n5FkYhH+EFQsB54QDhEKpdZEg4hyfv3x8yum2SzO0l2N7vJ+5lHHrs7MzvzmdnZnfd8TlFVjDHGGGMSTUpjJ8AYY4wxJhQLUowxxhiTkCxIMcYYY0xCsiDFGGOMMQnJghRjjDHGJCQLUowxxhiTkCxIMQlBRHqJiIpIC/f1v0VkRhy2e7uI/DVG675ARJbEYt11JSIzReSdxk5HOCJSICIXN9K280Xkqzhu72MRyfewXJmIHB+HJNVJQ743kc7F4O9+9WUjHQ+vx9UkDwtSjGcislFE9rs/FN+IyJMi0i4W21LVH6nqUx7TdGos0hC0jXQRqRSRh+ryPlVdoKrjYpWuxuBenA6550CZiHwqIj9uxPQUiMi3InJYHd+nIvKDWKWr2rbmi8j/BE9T1QxVLYj0XlVtp6obaltPHdMRt+9vQ4T77kc6Hl6Pq0keFqSYujpdVdsBg4AhwK+qLyCOpnRuXQR8C5xb14thPPhzn+LoOfdi0Q64FviriBwT5zQgIr2AkwEFJsd7+0mqOX5/TRKzE9HUi6puBf4NDIDAHe1vRORdYB9wvIikicjjIrJNRLaKyP+ISKq7fKqI3CMiO0VkAzAxeP3Vs/5F5BL3rr1URD4RkUEi8gxwHPBP9+7wRnfZoSLynoiUiMja4OxfN1fkLXc9rwOdPezuRTg/5oeA06ulU0XkMhH5wr2j/7OIiDuvela1isgV7rKlIjJXRHqLSKGI7BGR50WkVbV9/lJEdovIYhHpWm1dV4rIF8AXQdOuFpEN7nG9u/rFxj3m34pIsYj8KGj6TPd9pe68CzwcF1T1NaAU6O0x3cNEZJWI+NzHYaHWKyJdRORDEbk+zOYvAlYA84EqRYMhzp/AZyEiy93Ja93zZlrQcr8Qke3uOTsraPph7rHb7OZCPCIird15+SLyVaj3ishs4ALgRndb/3SnB3IA3e/CLSKy3j3+q0WkhztPReQHodYjIjeIyIvV9vsBEbkvzDEDPH9/u7qf327387yk2moOF5Hn3DS/LyLZQem4KWh/PhGRM6u9V9y0+kRknYiMqe2zq/amWo9HiOOaEpSOXe736wh33uEi8ld3eol7LsY90DYeqKr927+nf2AjcKr7vAfwMTDXfV0AbAYygBZAS2AR8CjQFjgaWAlc6i5/GbDOXc8RwDKcO+IWQeu72H1+NrAV585PgB8APaunyX3dDdgFnIYThI91Xx/lzi8E/ggcBozEucD+Ncw+nwx8B3QCHgAWV5uvwCtAR5yAaQcwwZ03E3in2rKLgQ7ucfoOWAocD6QBnwAz3GVPAXbi3PEe5m57ebV1ve4eu9ZB05a5044DPg86hjNxgqxLgFTgcuBr93i2BfYAfd1luwAZtRyP2/3Hy33vRKAE6Bgp3W66vgWmu+fIee7rI4M/c6CXm/bZEc7HL4ErgMHuvh0TNK/Av+9hPosfBL3OB8qBO3HO3dNwLtad3Pn3uZ/dEUB74J/API/vnQ/8T5jv0g3Af4C+7jHNDjomgXRWX4/7Oe0NOvYtgO3A4Ch9f98CHgIOB3Jwzu0xQefBIWCqu+z1QDHQMug72xXnOzjNTWeXoM+iHLjOfe80wAccEeK7X+vn5uG4XosTxHbHORcfBf7mzrvU/Qzb4HwfBgMdGvs31v5DnLeNnQD7T55/9wegDOeitMn9AfNfIAuAO4OWPQbnItw6aNp5wDL3+ZvAZUHzxlF7kPIacE2YNAUHKb8Enqm2zGs4d9rHuT+ObYPmPUv4IOUvwCL3eZ77w3x00HwFRgS9fh64yX0e6gd2eNDr1cAvg17/AbjPff448Pugee3cbfcKWtcp1dKquAGS+/oKYGlQWr4MmtfGXf5YnCClBPhx8OdVy/G4HTjoLr8PqABuDJpfa7pxgpOV1dZXCMwM+sz/6H6m50VIxwh3vZ3d1+uA64LmB86fMJ9F9SBlv//8c6dtB4biBA57gd5B8/KA4kjvdZ/PJ/zF9DPgjFr2M9JF+d/AJe7zScAnUfr+9nA/2/ZB0+YB84POgxVB81KAbcDJtWx7jX8f3c/ia0CC5q8Epof47tf6uXk4rp/iBlXu6y7uOdMC+AnwHpAV7jyz/8b/t+IeU1dTVLWjqvZU1StUdX/QvC1Bz3vi3CVtc7NTS3DuZI5253ettvymMNvsAaz3mL6ewNn+bbrbHYHzA9UV+FZV93rZrpudfzawAEBVC3HuNs+vtuh/g57vw7kw1+aboOf7Q7z2v7drcNpUtQwnR6hb0PLBxy/UtE3uemqkU1X3uU/bucdjGk7u1jYR+ZeI9AuzD8+750AbnGKei0TkUg/prjIvKI3B+3QBTq7Z38NsH5ygc4mq7nRfP0u1Ip962KWq5UGv/Z/lUThB3eqgc+r/3OmR3utFXc7v6p4CLnSfXwg8E2F5r9/frsBuVS0Nmlb9swosr6qVwFfu+xCRi0RkTdDxGkDVotWtqk7kELTu4HM1GnoCLwWl4VOcwOsYnOP0GrBQRL4Wkd+LSMsob99EgQUpJpqCf3S24OSkdHZ/FDuqagdVzXDnb8P5cfY7Lsx6txBU5yHMNv3LPhO0zY6q2lZV73K32UlE2nrc7pk4RTMPich/ReS/OD/SF4V5T7R8jfMjC4Cb5iNxLuB+1fcdah7Tr71sTFVfU9WxOMHcOuB/Pb5vI87dvL+uTrh0V5kXlMbgfbodp7joWXHrL1XnBo/nAKOCPpfrgOygehF7cQILv2O97E8tduIEkBlB51SaOhVQvQj1OQULd35HWs8iIEtEBuDkpCzwmKZI6/8aOEJE2gdNq/5ZBc41ceo+dQe+FpGeOOfPVTjFVh2Bj3BypPy6iUjwa8/nai3pDWUL8KNqvwWHq+pWVT2kqneoan9gGM6xi8f32tSRBSkmJlR1G7AE+IOIdHArsfUWkVHuIs8DV4tIdxHpBNwUZnV/Aa4XkcHi+IH7QwhOTkRwvwl/BU4XkfFuhcTD3YqN3VV1E1AE3CEirURkBNUqwlYzA3gCyMQpk88BhgM5IpJZpwNSd88Cs0QkR5wWRb8F/p8bFIRzg4h0citeXgM8F2lDInKMiEx2A4rvcIoEKrwkUkS6AxNw6jdESverwAkicr6ItBCnwmp/nDo9fodwcq/aAs9I6FYmU9z09ef7z+WHwNt8f6FZA5wlIm3EaWr802rrqH7e1MrNJfhf4F4ROdrd724iMt7L+z1s6y/AXBHp457fWSJypJf1qOoBnFynZ3GK0jZ7TFNYqroFpzhknvsdysI5hsFB0GAROUuc1mXX4pw7K3A+O8Wpw4I4lYgHVNvE0Tjf/5YicjbO5/dqHZMZ6bg+AvzG/1shIkeJyBnu89EikukGwntwzjtP57yJLwtSTCxdBLTCqRD6Lc6PaRd33v/iZLeuBd4H/lHbSlT1BeA3OD/EpTh3j0e4s+cBv3KzdK93f1zPAG7B+ZHcglMx0X+unw+cBOwGbgOeDrVNEekGjMGpI/LfoP/VOFn9DS1aCEtVlwJzgBdxcoB6A+d6eOvLOHVd1gD/wqkjEkkK8AucO9ndwCic+iy1mea2qCgDVgHvAndESreq7sK5Y/0FThHQjcCkoCIb3OUOAmfhXMieCBGozACeVNXNwZ8N8CBwgXvRvBen7sw3OEUi1XMYbgeecs+bcyIfIn6JU1F3hYjsAd7AqejqxeNAf3dbi0LM/yNO0L4E54L5ONC6Dut5CieQjlTUU1fn4dQl+hp4CbhNVV8Pmv8yTjGhvzL0WW4OxSc49asKcY5/Js45Euz/AX1wcql+A0x1z4+6iHRc/4RT2XmJiJTiBFAnufOOxfk92oNTDPQWzg2OSTBStVjQGJOsRESBPqr6ZWOnxcSPiByHU0R3rKruaez0GBNNlpNijDFJys1l+jmw0AIU0xTFu6dKY4wxUeDWIfoGp2XMhEZOjjExYcU9xhhjjElIVtxjjDHGmISUdMU9nTt31l69ejV2MowxxhgTBatXr96pqkeFmpd0QUqvXr0oKipq7GQYY4wxJgpEpNaev624xxhjjDEJyYIUY4wxxiQkC1KMMcYYk5AsSDHGGGNMQrIgxRhjjDEJKWZBiog8ISLbReSjWuaLiNwvIl+KyIciMihWaTHGGGNM8ollTsp8wnfV/COcUTD7ALOBh2OYFmOMMcYkmZj1k6Kqy0WkV5hFzgCeVqdf/hUi0lFEuqjqtlilqTb5+fkhpxcUFHheJhrriNd2bB1Ndx3R2k7HNR1DLlOSUxJyeijRWEei8HLMjEkGkb6Xifa9bcw6Kd2ALUGvv3Kn1SAis0WkSESKduzYEbME+bp3Z/OIEfi6d4/ZNpoaL8fMjqsxxpj6iOkAg25OyiuqOiDEvH8B81T1Hff1UuBGVV0dbp25ubkaix5nC30+xqxdy8HKSlqlpLA0O5u8tLSob6cu6SkoKSG/Y8dGTUc4Xo5Zoh1XY4wxiUVEVqtqbqh5jZmT8hXQI+h1d+DrRkoLBSUlHKyspAI4WFlJQUnjZUn7L+xziosZs3YthT5fo6UlHC/HLJGOqzHGmOTSmEHKYuAit5XPUMDXGPVR/PI7dqRVSgqpQKuUFPI7hi6Xi6TQ52Pepk1hA4tIyyTLhd3LMYvWcTXGGNP8xKzirIj8DcgHOovIV8BtQEsAVX0EeBU4DfgS2AfMilVavMhLS2NpdnbEIpZwxTDRKv7wX9j9yzTmhT3c/no5Zl6PqzHGGFNdLFv3nBdhvgJXxmr79ZGXlhb2IhopwAiVA1J9fV6WidaFvaH1WrwEVJGOmddlmpNkqG9kjDGJIGZBSlMUKcDwkgPiNZekoRf2aFRY9RJQmbqxisTGGOOdBSl1ECnASKTij2gEGPlffUWrAwc42KIFrcrLyf/qK+jZMybpbS4s8DPGGO8sSKkDr0FIIhR/RKNeS97y5Sx99lkKsrLI//BD8s4/H4YPj0Fqm49Eqm9kjDGJLqb9pMRCrPpJaYoaXPehsBDGjIGDB6FVK1i6FPLyop/QZsbqpBhjzPfC9ZNiQYoJr7AQCgogP98CFGOMMVEXLkix4h4TXl6eBSfGuCwXzJj4siDFGGM8sJZZxsRfY/Y4m3gKC2HePOfReJNEx8xLb8DG1CZZeoI2pimxnBS/eFYSbSr1PJKoYq3dBcdGcyr+sJZZxsSfBSl+BQXOxbaiwnksKIjNBTeJLuwRxeuYRYH1T1JTPHokbkpsiAdj4s+CFL/8fCdo8AcP+fmx2U6ULuwJcQcbr2MWBXYXXJX1SFw/NsSDMfFlQYpfXp6TqxHrYpgoXNgT5g42XscsCuwuuKqo9EhsgZ8xJsYsSAkWj+a2UbiwJ9QdbBI1Uba74O9FpUdiC/yMMTFmQUpjaOCF3e5gTUNFK8CwwM8YE0sWpCQhu4M10WABhjEm0VmQkqTsAtO8JUTFaWOMiTELUoxJMglTcdoYY2LMepxNVEnUk2tDWU+wdWM9nxpjmgvLSamrePQW25Q6fIOwx8xyBWqKVJRjFaeNMc2FBSl1Ea/gIZ693zZywJVQzakTgJegzSpOG2OaCyvuqYtQwUMs+Dt8S02NXU+u/uBhzhznMVbFShGOmT9XIBUsVwDvRTl5n3zCzc8+S94nn8Q3gcYYE0eWk1IX8eoGPh49ucYrtybCMbNcgao8FeU0teJAY4yphQUpdRHPbuBj3ZNrAgVc1pz6e56CtiQa2NEYYxpCVLWx01Anubm5WlRU1NjJaBriUSfFRJ/lpBhjmhARWa2quaHmWU5KsopGgJFE4+6YIEk0sKMxxjSEBSnJyO6kjQWYxphmwFr3JKN4tTIyxhhjGpEFKckoHk2UjTHGmEZmxT3JyOokJCxPA/9ZhWVjjPHEgpRkZXUSoq6hIwt76uLf6hMZY4xnVtxjDN8HGHOKixmzdm29Bjv01Fus1ScyxhjPYhqkiMgEEflMRL4UkZtCzD9ORJaJyAci8qGInBbL9JiqbPTh70VjZGFPXfxbfSJjjPEsZsU9IpIK/BkYC3wFrBKRxaoaPNjIr4DnVfVhEekPvAr0ilWakoqvDHylkNYe0tpFffU2+nBV0RhZ2FNvsVafyFidJGM8i2WdlBOBL1V1A4CILATOAIKDFAU6uM/TgK9jmJ7k4SuDDz+DSoUUgay+UQ9UbPThqqI1hpCnLv6tPlHzZXWSjKmTWAYp3YAtQa+/Ak6qtsztwBIR+RnQFjg11IpEZDYwG+C4446LekITjq/UCVDAefSVRj1IiUbOQVNjYwiZmLNxl4ypk1jWSZEQ06oPFHQeMF9VuwOnAc+ISI00qepjqpqrqrlHHXVUDJKaYNLaOzko4DymtY/6Jvw5B3PT05t9UU9TZXWOEpDVSTKmTiLmpIjIi8ATwL9VtbIO6/4K6BH0ujs1i3N+CkwAUNVCETkc6Axsr8N2Eks0ypvT2jlFPDGskwLNMOegGdUFsDpHCcrqJBlTJ16Kex4GZgH3i8gLODkf6zy8bxXQR0TSga3AucD51ZbZDIwB5ovID4HDgR1eE59wolnenNYuZsFJs9TM6gJYnaMEZnWSjPEsYnGPqr6hqhcAg4CNwOsi8p6IzBKRlmHeVw5cBbwGfIrTiudjEblTRCa7i/0CuERE1gJ/A2aqavUioeRhfWAkrmb22XhqDm2MMQnOU8VZETkSuBCYDnwALABGADOA/Nrep6qv4jQrDp7266DnnwDD65rohOUvb/bfrVt5c+JoZp9NtForGWNMY5JIGRci8g+gH/AMTlHPtqB5RaqaG9skVpWbm6tFRUXx3GTdNKN6D0knHp+Nff7GGFMnIrK6tljCS5BympsjEjztMFX9Lopp9Czhg5R4iXFnb6Yemlm9F2OMiYZwQYqXJsj/E2JaYcOSZBrE39lb8Vbn0VfW2Cky0OzqvRhjTKzVWidFRI7F6ZCttYgM5Pt+TzoAbeKQNlMbr529RaPoIVKOjeXofK+Z1XsxxphYC1dxdjwwE6d/kz8GTS8FbolhmhpPslxw/Z29+bvND9XZWzSKHiJ1zx+H7vuTivWBYYwxUVVrkKKqTwFPiciPVfXFOKapccTzgtvQYMhLZ2/R6H47Uo6N1xydZAn+osH6wDDGmKgJV9xzoar+FeglIj+vPl9V/xjibckrXhfcaAVDkTp7i0bRQ6QcGy85OpbbYowxpp7CFfe0dR+bxxUlWhfciHU4Yj94IBCdoodIOTZecnTitb/GGGOanHDFPY+6j3fELzmNKBoXXC9BjJdgKFqiUfQQKccm4vw47m+yaE7FX8YY0wDhinvuD/dGVb06+slpZA294HrJNYjT4IGexONimUj7mwis+MsYYzwLV9yzOm6pSBYRiz885hokwuCB8bxYJsL+Jgor/jLGGM8ite4x1YW74CZTroFdLOul0Odr2Hg40Sr+siIjY5qkBv/GNDHhinvuU9VrReSfQI2+81V1coi3mWTJNbC6InVW6PMxZu1aDlZW0iolhaXZ2XX/EYlGIGtFRsY0SVH5jWliwhX3POM+3hOPhJgYCHe3nUy5PgmioKSEg5WVVAAHKyspKCmpZ25KhEA2Uk/BlgtmTJMUtd+YJiRccc9q9/EtEWmFMxKyAp+p6sE4pc/Ul6eWRkmS65Mg8jt2pFVKSuAuJ79jx+hvxEtPwZYLZkyTFJffmCQTLicFABGZCDwCrMcZvyddRC5V1X/HOnGmAexuO+ry0tJYmp0d2/JiLz0FWy6YMU1SXH5jkkzEIAX4AzBaVb8EEJHewL8AC1ISmd1tx0ReWlpsfzi89hRsuWDGNEkx/41JMl6ClO3+AMW1Adgeo/SYaLG77eRkgxQaY0xAuNY9Z7lPPxaRV4HnceqknA2sikPaTEM1p7vtSJVNIXma7SbSIIVejqsxxsRIuJyU04OefwOMcp/vADrFLEXG1JWXyqbWbLfuvBxXY4yJoXCte2bFMyHG1JuXyqZWkbjuvBxXY4yJIS+tew4HfgpkAIf7p6vqT2KYLmO881LZ1EtFYivaqMprJV5TN8lS7GhMAvBScfYZYB0wHrgTuAD4NJaJMqZOvFQ2jVSR2Io2arJKvNFnxY7G1ImXIOUHqnq2iJyhqk+JyLPAa7FOmDF14qWyabiKxFa0EVoiVeINJ1lywazY0Zg68RKkHHIfS0RkAPBfoFfMUmRMY7CijeSVTLlg1n+RMXXiJUh5TEQ6AXOAxUA797kx0fHuClhfDL3TYfjQ+i/TEF6LNpLljr05SaZcMOu/yJg6iRikqOpf3KdvAcfHNjmm2Xl3BZSVQ/d05/HdFTWDEC/LREP/TOjWq/a722S6Y29Oki0XrDn1X2RMA6VEWkBEjhSRB0TkfRFZLSL3iciR8UicaQbWF0PLFpDaAlq0cF7XY5lCn495mzZR6PPVLx3+Co3FW51HX1nNZULdsTd1vjLYvC308fAyPx78uWBz51rgaEwT46W4ZyGwHPix+/oC4Dng1FglyjQjvd3cEQXKy53XdVym0OdjzNq1gZFDl2Zn133sCy8VGpPtjr2hIrVESaSWKslSwdcYUycRc1KAI1R1rqoWu///A9j40SY6hg+Fdi1ga7HzGKoYJ8IyBSUlHKyspAI4WFlJQUlJ3dPhr9AItVdo9HLHngg5C9ESKnCry3xjjGkgLzkpy0TkXJyxewCm4oyCHJGITAD+BKQCf1HVu0Iscw5wO8598lpVPd/Luk0TMnxoxDomhQN+SEH3Ls7w5dXm5XfsSKuUlEBOSn7HesTQXis0hrtjT6SchWiI1BLFWqoYY2JMVDX0DJFSnMBBgLZApTsrBShT1Q5hVyySCnwOjAW+whmU8DxV/SRomT44wc8pqvqtiBytqmFHWM7NzdWioiIv+2aaCC/FOYVf/5eCHTvJP6ozeV2PjV1iwvUWunmbU6fFL70bHNcldmmJh0i9o1rvqcaYBhKR1aqaG2peuLF7GnpbdCLwpapucBOxEDgD+CRomUuAP6vqt+42wwYopnkKVZxTJUjxlZG3fit5lQp7tkLbGLWeiJRTEq2chUS68EdqiWItVYwxMeSluAcRmQyMdF8WqOorHt7WDdgS9Por4KRqy5zgrv9dnCKh21X1/0JsfzYwG+C4447zkmTThEQszolXL56RthONPjCSrcjI+o2ps0Kfj4KSEqfosq4VvI1pZrwMMHgXMARY4E66RkRGqOpNkd4aYlr1sqUWQB8gH+gOvC0iA1S1Ss1HVX0MeAyc4p5IaTZNS15aGkuzs2v/YY9X3Qgv22lozkI0A65YBxDWb0ydRaUlmjHNiJeclNOAHFWtBBCRp4APgEhByldAj6DX3YGvQyyzQlUPAcUi8hlO0LLKQ7pMM5KXllb7j3m8evGMx3aiFXDFI4BIpp5eE0TEoktjTBVemiBD1SbHXr9Rq4A+IpIuIq2Ac3G61Q+2CBgNICKdcYp/NnhcvzHfS2vnVFKNddFIrLfjD4TSuzWsqKegAH5wAkyb7jzGouM5f78xqanNo9+YKPAXXaZC/VuiGdOMeMlJmQd8ICLLcIpwRgI3R3qTqpaLyFU4IyanAk+o6scicidQpKqL3XnjROQToAK4QVV31XNfjGkaolEZdeRoGHSy01PvoXKnf5lo8zreUTwkUmXjMCIWXRpjqqi1CTKAiAhOMU05Tr0UAf6fqv43PsmryZogG+PB5m1Q/BXOV1YhvXvyN4euTbJVNjbGVFGvJsgAqqoiskhVB1OzqMYYk6jS2kNKinvhTmnaHa3Fq3WXMSbuvOQBrxCRIapqlVmNSRbxqkycCKznW2OaLC9BymjgMhHZCOzFzT9W1axYJswY00DNpaO15hSQGdPMeAlSfhTzVBhjTEM0l4DMmGam1iBFRA4HLgN+APwHeFxVy+OVMGNME5EkLW+MMYknXE7KU8Ah4G2c3JT+wDXxSJQxpomwljfGmAYIF6T0V9VMABF5HFgZnyQZY+IiHjkc1vLGGNMA4YKUQ/4nbsdscUiOMSYu4pXD0dRa3ljRlTFxFS5IyRaRPe5zAVq7r/2tezrEPHXGmNiIVw5HU2p5Y0VXJh4sEK6i1iBFVVPjmRBjTByltQc0PjkcTaXljRVdmVizQLgGrwMMGmOakk/+A9ddAU884jx+8p/GTlHi8xddQdMoujJRV+jzMW/TJgp9vvqtIFQg3MzFYNQxY0zCKyiADz+AD4qcUYwLChp3gMBk0JSKrkzUFfp8jFm7loOVlbRKSWFpdnbdB5BsanW4osByUoxpjvLzoVUrJ0Bp1cp5nch8Zc6gib6yxk3HJ/+BBfMt58nUUFBSwsHKSiqAg5WVFJSU1H0lae0g5RBs+sJ5tEA4/CjIACJyFbBAVb+NT5LC69q1q86ePbuxk2FM8tuzB0pKoGNH6JDA9eDLK2DvPlCcavtt20CLRqgyt2cPrF0LlZXOoI3Z2Yl93Exc7SkvZ21ZGZU4d//Z7drRoUUdCyua6Tl2xx131G8UZNexwCoReR94AnhNI0U2xpjE16FDcvwAllc4AQo4j+UVjROklJQ4Fw9V57GkJDmOn4mLDi1akN2uHSXl5XRs0aLuAQrYORZCxJwUAHE6SRkHzAJygedxuslfH9vk1ZSbm6tFRUXx3qwxprEkSouHwkIYMwYOHnSKyJYutXo8Jrqa6TkmIg3KSUFVVUT+C/wXKAc6AX8XkddV9cboJdUYY6pJlAqreXnORaOgwKnD0wwuHnFRWGjH1C+e51iSHHcvdVKuBmYAO4G/AItU9ZCIpABfqGrv2Cfze5aTYoypj0Kfj4KSEvI7dqx7qwsTG80056DRJdhxb2hOSmfgLFXdFDxRVStFZFI0EmiMMbFU6PMxZs0aDqrSSoSlOTkWqCSCggLnQllR4TxaU/j4SKLj7qUJcnr1AEVEngFQ1U9jkipjTNNRWIML8PwAACAASURBVAjz5jmPjaTgv9s5qOo0D1Wl4L/bGy0tJkiyNYVvKjwc9wZ3TBclXnJSMoJfiEgqMDg2yTHGNCkJkq2cL6m0Ag4CrdzXxoNYjyPT1Or5JMu4OxGOe1Q6pouSWoMUEbkZuIXvBxYEp5eCg8BjcUibMSbZJUi2ct4xR7P0vzspqCwnP6UFecccHfc0eJYoF7p4tarKy0v+4AQSpxWaV/0zoVuvkL3ahuqYLuGCFFWdB8wTkXmqenMc02SMaSr82cr+nJRQ2fnxuCintSMvuz95iXDxDyeRLnQ2oGLdJNPxinCe5XfsSKuUlEBOSn7Hjo2W1HA5Kf1UdR3wgogMqj5fVd+PacqMMckvUna+14tyNJpLJsNozIl0obNxZOommY5XhPMsLy2NpdnZCdEaLlydlJ8Ds4E/hJinwCkxSZExpmkJl53v5aLsoV5Lk2lenNYe0MS40MWrf5pEKd5qqETpzwcP3wcPAVVeWlpCfJfCFffMdh9Hxy85xphmxcvdZ4R6LZ4r+SVD51Wf/AeuuxoyMuHj/8Cf72/ctMY69ymRireiIQFy6zx9HxIooIokYuseEbkSZ4DBEvd1J+A8VX0o1okzxjRxXn4sI9Rr8VTJL0FaGUVUUAAffgAfFDnNQ2NZ0fjdFbC+GHqnw/ChsdlGJIlUvNVEeK70mgABlRde+km5xB+gALijIV8SuyQZY5qVtHZwXJfafzD99Vrmzg0ZXPgr+aVC7ZX8QuXGJKJ49Rvy7gooK4fu6c7juytis51I/Dlp0PjFW02Ep+9DEvHST0qKiIh/5GO3n5RWsU2WMcYECVOvxVMlPy+tjBJBvPoNWV/sBCipLZwahuuLGyc3JYmKHZJFIlV6jQYvY/fcDfQCHsE5nS8DtqjqL2KeuhBs7B5jTL0kQ52UePHnpLRoAeXl0K5F4xX5mGYv3Ng9Xop7fgm8CVwOXAksBWzk4xB69epFZmYmOTk55OY6x3v37t2MHTuWPn36MHbsWL799lsAXnzxRTIyMjj55JPZtWsXAOvXr+fcc89ttPQb06Tl5cHNN1uAAk5A0q4FbC0OH6AkwJAGpnmLmJPSoJWLTAD+BKQCf1HVu2pZbirwAjBEVcNmkyRyTkqvXr0oKiqic+fOgWk33ngjRxxxBDfddBN33XUX3377Lb/73e8YNmwYr732GgsXLuTAgQP87Gc/47zzzuPOO++kT58+jbgXxhhD8lQ2NkmvXqMgi8jzqnqOiPwHp5inClXNirDRVODPwFjgK2CViCxW1U+qLdceuBr4fxH3xIP58+ezcePGaKwqoFevXsycObNe73355ZcpcCvpzZgxg/z8fH73u9+RkpLCd999x759+zjssMN4++236dKliwUoxpjEkCBDGiQVK1KMunAVZ69xHyfVc90nAl+q6gYAEVkInAF8Um25ucDvgevruZ2EISKMGzcOEeHSSy9l9uzZfPPNN3Tp0gWALl26sH27M/rqbbfdxvjx4+natSt//etfOeecc1i4cGFjJt8YY76XSJWNk6HDN8t5iolwnbltc59eoaq/DJ4nIr/DqasSTjdgS9Drr4CTqq1nINBDVV8RkVqDFBGZjdP7Lccdd1zYjdY3xyMa3n33Xbp27cr27dsZO3Ys/fr1q3XZsWPHMnbsWACeeuopTjvtND777DPuueceOnXqxJ/+9CfatGkTr6QbY0xViTJCcbJ0+GY5TzHhpeLs2BDTfuThfRJiWqDYSERSgHuBiK2EVPUxVc1V1dyjjjrKw6YbR9euXQE4+uijOfPMM1m5ciXHHHMM27Y58d62bds4+uiqo6/u27ePp556iiuuuIKbb76ZJ554gsGDB7NgwYK4p98YY6pIhMrGoTp8S0Tx6uOmmak1SBGRy936KH1F5MOg/2LgQw/r/groEfS6O/B10Ov2wACgQEQ2AkOBxSISsvJMotu7dy+lpaWB50uWLGHAgAFMnjyZp556CnByTM4444wq7/v973/PNddcQ8uWLdm/fz8iQkpKCvv27Yv7PhhjTMJJlg7fInQ6aOonXJ2UZ4F/A/OAm4Kml6rqbg/rXgX0EZF0YCtwLnC+f6aq+oBAMxgRKQCuj9S6J1F98803nHnmmQCUl5dz/vnnM2HCBIYMGcI555zD448/znHHHccLL7wQeM/XX39NUVERt99+OwC/+MUvGDp0KB07dmTRokWNsRvGmGSQDHU0oiWZOnwLN5hmPDWh88NTE2S3pc4xBAU1qrrZw/tOA+7DaYL8hKr+RkTuBIpUdXG1ZQvwEKQkchNkY4yJuWSpo2EaRxKeH/Vqghz05quA24FvgEp3sgJhmyADqOqrwKvVpv26lmXzI63PGGOaPRuUz4TTxM4PL2P3XAv0VdVdsU6MMaYZsr4l6sZfR8N/p5yodTRM42hi54eXIGUL4It1QowxzZD1LVF3yVRHw8RfEzs/vAQpG3Ba4PwL+M4/UVX/GLNUGWOaB+tbon7S2iX9xcfEUBM6P7wEKZvd/1buvzHGRIf1ampMYkqQ70PEIEVV7wAQkbaqujf2STLGNBtNrVfTBPlhN6ZBEqiFUMQeZ0UkT0Q+AT51X2eLyEMxT1kSKSkp4aGHEuuQ/Pa3vw0837hxIwMGDIjKejdu3Mizzz4beF1UVMTVV18d9j2nnXYaJSUlCXmcTAJoKr2a+n/Yi7c6j76y6KYxEfnKYPO25rGvzUkC9fLrpVv8+4DxwC4AVV0LjIxlopJNuItvRUVFnFPjCA5Soql6kJKbm8v9998f9j2vvvoqHTt2tCDFJK5o9GqaQD/scdEcg7LmIoF6+fUSpKCqW6pNapwrb4K66aabWL9+PTk5Odxwww0UFBQwevRozj//fDIzM2vkZNxzzz2BXmbXr1/PhAkTGDx4MCeffDLr1q2rsf6VK1cybNgwBg4cyLBhw/jss88AmD9/PldddVVguUmTJlFQUMBNN93E/v37ycnJ4YILLgCcYOmSSy4hIyODcePGsX///rDbnzlzJldffTXDhg3j+OOP5+9//3tgX99++21ycnK49957KSgoYNIkZ6DssrIyZs2aRWZmJllZWbz44osA9OrVi507d9Y4TtOnT+fll18OpP+CCy5g8eIqffwZEx/+FhHp3eqftZ1AP+xxkWxBmeX6eBeN70O0qGrYf+DvwDDgfZyKs9cDCyO9L1b/gwcP1oYYNWpUyP+GKC4u1oyMjMDrZcuWaZs2bXTDhg0h599999162223qarqKaecop9//rmqqq5YsUJHjx5dY/0+n08PHTqkqqqvv/66nnXWWaqq+uSTT+qVV14ZWG7ixIm6bNkyVVVt27ZtlfSlpqbqBx98oKqqZ599tj7zzDNhtz9jxgydOnWqVlRU6Mcff6y9e/cO7NvEiROr7Kv/9Y033qjXXHNNYN7u3btVVbVnz566Y8eOGsehoKBAzzjjDFVVLSkp0V69egX205ikVFKquulr57GpKylVXV6kWrDKeUzkfU6mtDZDOL3Qh7zme2ndcxnwJ6AbzqCBS4ArYxEwNSUnnngi6enpYZcpKyvjvffe4+yzzw5M++6772os5/P5mDFjBl988QUiwqFDh+qcnvT0dHJycgAYPHgwGzdujLj9KVOmkJKSQv/+/fnmm28ibuONN95g4cKFgdedOnUKu/yoUaO48sor2b59O//4xz/48Y9/TIsWXk5JYxJUE2r6GVEy9cfRxHphbU68tO7ZCVwQh7TERUFBQVy207Zt28DzFi1aUFlZGXh94MABACorK+nYsSNr1qwJu645c+YwevRoXnrpJTZu3Ei+20yztvWGcthhhwWep6amsn///ojbD36PehjjSVURkYjLBZs+fToLFixg4cKFPPHEE3V6rzGm/gp9PgpKSsjv2JG8tLT6rSRZgrIm1gtrRE2oF2cvrXuOEpFbROQxEXnC/x+PxCWL9u3bU1pae3nsMcccw/bt29m1axffffcdr7zyCgAdOnQgPT09MDKyqrJ27doa7/f5fHTr1g1w6qH49erVizVr1lBZWcmWLVtYuXJlYF7Lli0j5rh43b7XfR03bhwPPvhg4PW3334b8b0zZ87kvvvuAyAjIyPsto0x0VHo8zFm7VrmFBczZu1aCn1NvFPxRKpjEeu6Mf5enOfMcR4LC2OznTjxUnH2ZSANeAP4V9C/cR155JEMHz6cAQMGcMMNN9SY37JlS379619z0kknMWnSJPr16xeYt2DBAh5//HGys7PJyMioUpHU78Ybb+Tmm29m+PDhVVoLDR8+nPT0dDIzM7n++usZNGhQYN7s2bPJysoKVJytjZftB8vKyqJFixZkZ2dz7733Vpn3q1/9im+//ZYBAwaQnZ3NsmXLIh6nY445hh/+8IfMmjUr7HaNMdFTUFLCwcpKKoCDlZUUlJQ0dpJiL60dHNel8QOUWLeICtWLcxKTSNn4IrJGVXPilJ6IcnNztaioqLGTYaJk3759ZGZm8v7775NW3yxnY0xVETqV8+ekHKyspFVKCkuzs+tf5GO827zNCVD80rs5gVM0JeF4WCKyWlVzQ83zUkvxFRE5TVVfjXK6TDP3xhtv8JOf/ISf//znFqAYEy0eegvNS0tjaXZ2w+ukmLqJR92YROnFOUpqzUkRkVJAAQHa4gwueMh9raraIV6JDGY5KcYYE0Y87tZN/dnQCTXUKydFVZt49WdjTDxEpRWJ8a65tWRJNsnSIipBRCzuEZGlqjom0jRjjKnO6j40gmTqv8SYCGoNUkTkcJxins4i0gmnmAegA9A1DmkzxiS5UK1ILEiJA7tbN01EuJyUS4FrcQKS94Om7wH+HMtEGWOahvyOHWmVkhLIScnv2LGxk2SMSSK19pOiqn9S1XTgelVND/rPVtUHa3ufiY3qIwgHD+xXHw19/69//WveeOONer+/rm6//XbuueceT9tes2YNr75a98Zo+fn5hKqUfd9997Fv377A63btQt+hPvLIIzz99NOetlV9cMj6qj54ZaLxtyKZm56e+EU9hYUwb17Sd37VLNnggU2WlybIPhG5qPpEVfX2a2yiwh+kXHHFFY2dFADuvPPOBq+jvLy8XmP1RNr2mjVrKCoq4rTTTqtv0qq47777uPDCC2nTpk3Y5S677LKobK+pyUtLS+zgBJKybwnj8tDk2iQvLz3ODgn6Pxm4HZgcwzQlpSlTpjB48GAyMjJ47LHHQi7Tq1cvbrnlFvLy8sjNzeX9999n/Pjx9O7dm0ceeSSw3N13382QIUPIysritttuA+Cmm25i/fr15OTkBHprLSsrY+rUqfTr148LLrggML7O0qVLGThwIJmZmfzkJz8JDBr4f//3f/Tr148RI0bwj3/8I2Qa58+fz5QpUzj99NNJT0/nwQcf5I9//CMDBw5k6NCh7N69G3C6s//73/8eSFv//v3Jysri+uuvD8y/7LLLOPnkkznhhBMCQwHMnz+fs88+m9NPP51x48bVur8Av/nNb+jbty+nnnoqn332WWB68LZXrVrFsGHDyM7O5sQTT8Tn8/HrX/+a5557jpycHJ577jn27t3LT37yE4YMGcLAgQMDveru37+fc889l6ysLKZNm8b+/ftrHI/777+fr7/+mtGjRzN69OjA9FtvvZXs7GyGDh0aGHwxOLfn/vvvDxyTc889N+Sx3rJlCxMmTKBv377ccccdgel//OMfGTBgAAMGDAgMGRBuut+GDRsYOHAgq1atCrk9E0YT66WzWQk1eKBpOmobHrm2f5wu8hfX9X3R+h88eHC9h4NWVR1Vy19D7dq1S1VV9+3bpxkZGbpz584ay/Ts2VMfeughVVW99tprNTMzU/fs2aPbt2/Xo446SlVVX3vtNb3kkku0srJSKyoqdOLEifrWW29pcXGxZmRkBNa1bNky7dChg27ZskUrKip06NCh+vbbb+v+/fu1e/fu+tlnn6mq6vTp0/Xee+8NTP/888+1srJSzz77bJ04cWKNND755JPau3fvQLo6dOigDz/8cCDN9957r6qqzpgxQ1944QXdtWuXnnDCCVpZWamqqt9++21g/vjx47WiokI///xz7datm+7fv1+ffPJJ7datW+B41ba/RUVFOmDAAN27d6/6fD7t3bu33n333VW2/d1332l6erquXLlSVVV9Pp8eOnRIn3zySb3yyisD+3TzzTfrM888E0hfnz59tKysTP/whz/orFmzVFV17dq1mpqaqqtWrQr5ue3YsSPwGtDFixerquoNN9ygc+fOVVXV2267LZDGLl266IEDB6ock+rH+dhjj9WdO3cGzplVq1YF9rusrExLS0u1f//++v7779c63X9erFu3TnNycvSDDz6osS3jwXvvqbZurZqa6jy+915jp8h4VVKqurxItWCV81hS2tgpMnUEFGkt1/y657XDPqBPFOOkJuH+++/npZdeApw75C+++IIjjzyyxnKTJzuZUJmZmZSVldG+fXvat2/P4YcfTklJCUuWLGHJkiUMHDgQcHJLvvjiC4477rga6zrxxBPp3r07ADk5OWzcuJH27duTnp7OCSecAMCMGTP485//TH5+Punp6fTp43x0F154Ya05PqNHjw6kKy0tjdNPPz2Q5g8//LDKsh06dODwww/n4osvZuLEiVXquZxzzjmkpKTQp08fjj/+eNatWwfA2LFjOeKIIwBq3d/S0lLOPPPMQBGL/7gF++yzz+jSpQtDhgwJpCWUJUuWsHjx4kAux4EDB9i8eTPLly/n6quvBpwxibKyskK+v7pWrVoF9nPw4MG8/vrrNZbxj5s0ZcoUpkyZEnI9Y8eODZwjZ511Fu+88w4iwplnnhkYRfuss87i7bffRlVDTp88eTI7duzgjDPO4MUXX7RBGusrgXrptH5l6siaXNdLspxnXvpJ+SdOz7PgFA/1B16IZaJiqYCC6K+zoIA33niDwsJC2rRpQ35+PgcOHAi57GGHHQZASkpK4Ln/dXl5OarKzTffzKWXXlrlfRs3bqx1XQCpqamB99dGRGqdV9t6g9PpT2OwFi1asHLlSpYuXcrChQt58MEHefPNN0Nuz//af6EFat3f++67L2J6VdXTPqkqL774In379q0xz+sxCdayZcvA+/zHvbp//etfLF++nMWLFzN37lw+/vjjGvVvQh2f2j6/cJ9rWloaPXr04N1337UgpSHy8hq9Hor1KxNaxAtqEjW5ToTgIJnOMy91Uu4B/uD+zwNGquovY5qqJOPz+ejUqRNt2rRh3bp1rFixot7rGj9+PE888QRlZU4t9a1bt7J9+3bat29PaWnkstZ+/fqxceNGvvzySwCeeeYZRo0aRb9+/SguLmb9+vUA/O1vf6t3GoOVlZXh8/k47bTTuO+++1izZk1g3gsvvEBlZSXr169nw4YNIYOE2vZ35MiRvPTSS+zfv5/S0lL++c9/htzXr7/+OlAHo7S0lPLy8hrHavz48TzwwAOBC/0HH3wAwMiRI1mwYAEAH330UY1cIj+vx96vsrKSLVu2MHr0aH7/+99TUlIS2L9gr7/+Ort372b//v0sWrSI4cOHM3LkSBYtWsS+ffvYu3cvL730EieffHKt08HJ2Vm0aBFPP/00zz77rOd0msTTLEcnjsB/QZ1TXMyYtWsp9PkaO0n1lij74uk8S5DWbhFzUlT1reDXIjJcRG5W1Stjl6zkMmHCBB555BGysrLo27cvQ4cOrfe6xo0bx6effkqee0fXrl07/vrXv9K7d2+GDx/OgAED+NGPfsTEiRNDvv/www/nySef5Oyzz6a8vJwhQ4Zw2WWXcdhhh/HYY48xceJEOnfuzIgRI/joo4/qnU6/0tJSzjjjDA4cOICqcu+99wbm9e3bl1GjRvHNN9/wyCOPcPjhh3ve30GDBjFt2jRycnLo2bNn4IIcrFWrVjz33HP87Gc/Y//+/bRu3Zo33niD0aNHc9ddd5GTk8PNN9/MnDlzuPbaa8nKykJV6dWrF6+88gqXX345s2bNIisri5ycHE488cSQ+zh79mx+9KMf0aVLF5YtWxbxmFRUVHDhhRfi8/lQVa677jo6hugfZMSIEUyfPp0vv/yS888/n9xcZ+iKmTNnBtJy8cUXB4rCQk3357C1bduWV155hbFjx9K2bVvOOOOMiOk0icf6lampKXUImCj7EvE8S6DWbrUOMFhlIZEc4HzgHKAY+IeqPhDjtIVkAwwmh5kzZzJp0iSmTp3a2EkxJqkkQnFAIola0URhYaPXOUqkYpaw59m8eTBnjtPaLTUV5s6Fm2+OWVrqNcCgiJwAnAucB+wCnsMJakbX9h5jjDENkxT9ysSRv0PAcIFbxMAuQXIGvOxLPNNS6/bz853j5D9e+fnxTFoV4Yp71gFvA6er6pcAInJdXVYuIhOAPwGpwF9U9a5q838OXAyUAzuAn6jqprpswySm+fPnN3YSjDFNRLgLqqfciVD94NQnSPGVNbgVUVIEoQnU2i1ckPJjnJyUZSLyf8BCvh9kMCIRScUZ42cs8BWwSkQWq+onQYt9AOSq6j4RuRz4PTCtjvtgjDGmmfJUzyMaOQOJ1LNtFIKliBKgtRuEH7vnJVWdBvQDCoDrgGNE5GERGedh3ScCX6rqBlU9iBPkVKnNp6rLVNU/KMoKoHs99sEYY0wz5a8Emgq1Vzb25wzMnVt7UU+k8X8SpWdbf7BUvNV5bOLjFXlp3bMXWAAsEJEjgLOBm4AlEd7aDdgS9Por4KQwy/8U+HeoGSIyG5gNhOzUzBgTG1aJs3lLhs/fcz2PcDkDXnJJ0to78/zLpLWP7o54FSpYSpI+YuqjTj3Oqupu4FH3P5JQRUMhmxKJyIVALjCqlu0+BjwGTuseT4k1xjRIIrVESBoJ0IIkWqL2+cehaKLB9Ty8XPgTpWfbtPYUSiUFleXkp7Qgr7GCpTjx0plbfX0F9Ah63R34uvpCInIqcCswWVW/i2F64i54ILxElizpNPFlHYvVkb8FyZw5zmMjd4LVUFH5/JOlaMKfSwLhc0nS2sFxXRo156KQCsbofuZwkDG6n0IqGi0t8RDLIGUV0EdE0kWkFU4l3MXBC4jIQJxcmcmquj2GaWl2QnXVbkxdeCrrN99rYiMpR+XzT5R6HJH4c0nSuzVuhVgPCkpKOKjqBI+qTf7mIWZBiqqWA1cBrwGfAs+r6scicqeI+EeLuxtoB7wgImtEZHEtq4u+KHf5+/TTT5OVlUV2djbTp08PTF++fDnDhg3j+OOPD+RWlJWVMWbMGAYNGkRmZiYvv/wy4IzP069fP2bMmEFWVhZTp05l3759NbaVn5/Ptddey7BhwxgwYAArV64E4Pbbb2f27NmMGzeOiy66iIqKCm644QaGDBlCVlYWjz7qlNKpKldddRX9+/dn4sSJbN8eOj783//9X4YMGUJ2djY//vGP2bdvHz6fj169elFZWQnAvn376NGjB4cOHWLVqlVkZWWRl5fHDTfcwIABA6JybE3j8Jf1z01Pt6IeL/wtSFJTG71viWiIyufvNYciEXjIJSn0+Zi3aVOjds3f7G4eahseOVH/Bw8e7Hn451pFeVj2jz76SE844QTdsWOHqqru2rVLVVVnzJihU6dO1YqKCv3444+1d+/eqqp66NAh9fl8qqq6Y8cO7d27t1ZWVmpxcbEC+s4776iq6qxZs/Tuu++usb1Ro0bpxRdfrKqqb731lmZkZKiq6m233aaDBg3Sffv2qarqo48+qnPnzlVV1QMHDujgwYN1w4YN+uKLL+qpp56q5eXlunXrVk1LS9MXXnihxnZ27twZeH7rrbfq/fffr6qqkydP1jfffFNVVRcuXKg//elPVVU1IyND3333XVVV/eUvfxlIlzHNxnvvqf72tw3+TUmY7URDSanqpq+dxyT2XkmJtn7rLU1dtkxbv/WWvldSUs8VNfyze6+kRH+7cWP905BggCKt5Zpfp4qzTUa0OvZxvfnmm0ydOpXOnTsDcMQRRwTmTZkyhZSUFPr3788333wDOIHhLbfcwvLly0lJSWHr1q2BeT169GD48OEAXHjhhdx///1cf/31NbZ53nnnAc4geXv27KHEzfKbPHkyrVu3BmDJkiV8+OGHgRwcn8/HF198wfLlyznvvPNITU2la9eunHLKKSH366OPPuJXv/pVYIC88ePHAzBt2jSee+45Ro8ezcKFC7niiisoKSmhtLSUYcOGAXD++efzyiuv1PuYGpOU4tG3RIL0nupZEo1QHE5Uxt2J0meXFB3CRUks66Qkrihny6oqIqH7uTvssMOqLAewYMECduzYwerVq1mzZg3HHHMMBw4cAKixntrWW9tybdu2rbK9Bx54gDVr1rBmzRqKi4sZN25c2PUGmzlzJg8++CD/+c9/uO222wJpnDx5Mv/+97/ZvXs3q1ev5pRTTgnsmzEmxppY3ZdkEZViFvvs6qx5BileOvapgzFjxvD888+za9cuAHbv3h12eZ/Px9FHH03Lli1ZtmwZmzZ9PxLA5s2bKXTryfztb39jxIgRIdfx3HPPAfDOO++QlpZGWoioevz48Tz88MMcOnQIgM8//5y9e/cycuRIFi5cSEVFBdu2bat1ZN/S0lK6dOnCoUOHWLBgQWB6u3btOPHEE7nmmmuYNGkSqampdOrUifbt27NixQoAFi5cGPYYGJNoolHfIC51FppY3ZdkEZU6OvbZ1VnzLO6BqGbLZmRkcOuttzJq1ChSU1MZOHBg2LFrLrjgAk4//XRyc3PJycmhX79+gXk//OEPeeqpp7j00kvp06cPl19+ech1dOrUiWHDhrFnzx6eeOKJkMtcfPHFbNy4kUGDBqGqHHXUUSxatIgzzzyTN998k8zMTE444QRGjQrZPQ1z587lpJNOomfPnmRmZlJa+n3N/GnTpnH22WdTEHQn8Pjjj3PJJZfQtm1b8vPzQwZOxiSiaPQJErd+ZRJoXJXmpsHFYZX2PgAAFh5JREFULPbZ1ZkkWzZ9bm6uFhUVNXYyYmLjxo1MmjSJjz76KOxy+fn53HPPPeTmhhzZutGUlZXRrp1T9nzXXXexbds2/vSnPzVyqoyJbN6mTcwpLqYCZzTUuenp3NyzZ9zXYUxzJCKrVTXkBa355qSYqPvXv/7FvHnzKC8vp2fPnjYSskka/voG/lyQ+tQ3iMY6jDFVWU6KMcYQnXFqkmGsG2MSjeWkGGNMBNFo1tmcmoYCnsYqikrgFmk7TWjMJFOVBSnGGGPqzkOfH1GpTBxpO8nWb4ypk+bZBNkYY5JYInTP7qXPj6gMUhhpO1HqeyQhjqmpwXJSjDEmicStqXMk/j4//DkYIfr8iEpl4kjb8ZCOSBLmmJoaLCclhmbOnBnokj6RxSqd8+fP56qrror6eo1pzqKSOxENHjrFzEtLY2lqKnM3bWJpamr9LvyRthOFzjkT5piaGiwnpYkqLy+nRYvYf7zx2o4xxpFQTZ0jdYpZWEje2LHkNbS+SKTtNLBzzoQ6pqaK5puT4iuDzducxyh4+umnycrKIjs7m+nTpwemL1++nGHDhnH88ccHcivKysoYM2YMgwYNIjMzk5dffhlwOnPr168fM2bMICsri6lTp7Jv374a28rPz+faa69l2LBhDBgwgJUrVwJw++23M3v2bMaNG8dFF11ERUUFN9xwA0OGDCErK4tHH30UcMb0ueqqq+jfvz8TJ05k+/btIffJ63YOHDjArFmzyMzMZODAgVW62d+yZQsTJkygb9++3HHHHYHpU6ZMYfDgwWRkZPDYY4+F3P6dd97JkCFDGDBgALNnz0ZV+fTTTznxxBMDy2zcuJGsrCwAXn31Vfr168eIESO4+uqrmTRpUoRPzZjkE5Xu2eMlgcaqCVfnJKmOaXNT2/DIifo/ePDgho8LXVKqurxItWCV89jAIcQ/+ugjPeGEE3THjh2qqrpr1y5VVZ0xY4ZOnTpVKyoq9OOPP9bevXurquqhQ4fU5/OpquqOHTu0d+/eWllZqcXFxQroO++8o6qqs2bN0rvvvrvG9kaNGqUXX3yxqqq+9dZbmpGRoaqqt912mw4aNEj37dunqqqPPvqozp07V1VVDxw4oIMHD9YNGzboiy++qKeeeqqWl5fr1q1bNS0tTV944YV6b+eee+7RmTNnqqrqp59+qj169ND9+/frk08+qccee6zu3LlT9+3bpxkZGbpq1aoqx8g/fefOnTW2719GVfXCCy/UxYsXq6pqdna2rl+/XlVV77rrLp07d67u379fu3fvrhs2bFBV1XPPPVcnTpxY20dmkkxTG5o+5t57T/W3v3UeGzsdrVurpqY6j42UnvdKSrT1W29p6rJl2vqtt+w8SjBAkdZyzW+eOSm+Uqh0O7GrVOd1A7z55ptMnTqVzp07A3DEEUcE5k2ZMoWUlBT69+/PN998AziB4S233EJWVhannnoqW7duDczr0aMHw4cPB+DCCy/knXfeCbnN8847D4CRI0eyZ88eStwy1MmTJ9O6dWsAlixZwtNPP01OTg4nnXQSu3bt4osvvmD58uWcd955pKam0rVrV0455ZRa983Ldt55551A7lG/fv3o2bMnn3/+OQBjx47lyCOPpHXr1px11lmB/bn//vvJzs5m6NChbNmyhS+++KLGtpctW8ZJJ51EZmYmb775Jh9//DEA55xzDs8//zzgDLQ4bdo01q1bx/HHH096enqVdJvk56/UOKe4mDFr11rri0j8TXLnzHEe3QFLG0WUB3OtL091TgoLYd68xj1epobmWZkgrT2kiBOgpIjzugFUFREJOe+www6rshzAggUL2LFjB6tXr6Zly5b06tWLAwcOANRYT23rrW25tm3bVtneAw88wPjx46ss++qrr9a63vpupy7vLygo4I033qCwsJA2bdqQn58f2H+/AwcOcMUVV1BUVESPHj24/fbbA8v4Bzc866yzEBH69OnDBx984Gl/TPIJdYGx7PgwQhWxNGa/IVEczLW+ItY5sb5WElbzzElJawdZfSG9m/OY1q5BqxszZgzPP/88u3btAmD37t1hl/f5fBx99NG0bNmSZcuWsWnTpsC8zZs3U+hG8n/7298YMWJEyHU899xzgJOLkZaWFnLE4fHjx/Pwww9z6NAhAD7//HP27t3LyJEjWbhwIRUVFWzbtq1KHZL6bGfkyJEsWLAgsI3NmzfTt29fAF5//XV2797N/v37WbRoEcOHD8fn89GpUyfatGnDunXrWLFiRY11+gOSzp07U1ZWVqX1Ue/evUlNTWXu3LlMmzYNcHJwNmzYwMaNG6uk2yQ//wUmFaxSoxf+JrmpqfVukutVsvQtErHOide6M5bbEnfNMycFnMCkgcGJX0ZGBrfeeiujRo0iNTWVgQMHhh1c74ILLuD0008nNzeXnJwc+vXrF5j3wx/+kKeeeopLL72UPn36cPnll4dcR6dOnRg2bBh79uzhiSeeCLnMxRdfzMaNGxk0aBCqylFHHcWiRYs488wzefPNN8nMzOSEE05g1KhRtabVy3auuOIKLrvsMjIzM2nRogXz588P5CCNGDGC6dOn8+WXX3L++eeTm5tLZmYmjzzyCFlZWfTt25ehQ4fWWGfHjh255JJLyMzMpFevXgwZMqTK/GnTpnHDDTdQXFwMQOvWrXnooYeYMGECnTt3rlK51iQ3/wXGxsTxyF/EEuNu4pOtb5GwQxZ46WvFclsahQ0wmEA2btzIpEmT+Oijj8Iul5+fzz333ENubsjxmKImXtuJlrKyMtq1a4eqcuWVV9KnTx+uu+66xk6WMU3SvE2bmPP/27v74KiqNI/j3wccCYULMrxYlLwEd8JbKULYsAMEomaWZRaFrQFUEAkyCoisrMUuNbhV6wDrMqNVG3F9oWQUkUJgGNZdCocZEEYYlVIcXkWlFpjIpHQBGV5EAWny7B/3JnRCJyFJd7o7/ftUpXLv6ZN7Tp5Op58+995z/vhHLgHNgQXduzO3W7dkd6v+alv/Z+HC4DqfS5eCUaoFC2Du3MbuZZOkBQYlIyxZsoRly5bx7bff0r9/f6ZNm5bsLok0WU1ubpHarp2Jw8y2UncaSRERkXqJywrH6USrLSeERlJERCTuarzOoylKgTuVMk1m3t0jIiIiKU9JioiISDrJoFuhdbpHREQkXWTYrdAaSYmDkpISbr755rgcKzs7my+//DIux0p2m5MnT640CZuIiDRQCi3a2BiUpDRRkUikSbUjTVe6zFoqiaHnv44acUbhVJCxSUq8XxiRSISioiL69u3L2LFj+eabbwDYvHkz/fv355ZbbmHKlClcuHChxvJy586dY8SIESxZsuSKtq677jpmz55Nbm4uhYWFHD9+HAgmX3v88ccpKChg0aJFHD9+nDFjxpCXl0deXh7vvvsuACdOnGD48OEVc4lUdxv61bbz2WefUVhYSN++fSksLOTIkSMVx3jrrbcYOnQoPXr0YP369UAw8jR06FByc3PJzc3lvffea0joJY1p8cDMpue/HlJk0cbGkpFJSiJeGAcOHGDq1Kns3buX1q1b88ILL3D+/HkmT57M6tWr2bdvH5FIhBdffLHa8nJnz57lrrvuYsKECTz00ENXtPX111+Tm5vLzp07KSgoYN68eRWPnTp1iq1btzJ79mxmzZrFY489xo4dO1i7di0PPvggAPPmzSM/P59du3YxatSoSklFfdqZOXMmkyZNYu/evdx33308+uijFfVKSkrYunUrb775JtOnT+f8+fN07NiRTZs2sXPnTlavXl2pvmSWq1qdVuosXUYn9PzX06BBwWy3TTxBgQxNUhLxwujSpQtDhgwBYOLEibzzzjscOHCA7t2706NHDwCKiorYtm1bteXlRo8ezQMPPMCkSZNittWsWbOKhfXK2ypXXg7BKMbMmTPp168fo0aN4syZM3z11Vds27aNiRMnAjBy5Ejatm3boHa2b9/OhAkTALj//vsr1bv77rtp1qwZOTk53HTTTXz66adcvHixYl2ecePG8fHHH9cYW2m6tHhg/KXT6ISef6lNQu/uMbMRwCKCpR1+4e4/q/J4C+A1YABwArjH3UsS2SdIzHTOZnbFfnWnUWqb5XfIkCFs2LCBCRMmXHHc2tpu1apVxXZZWRnbt2+nZcuWtfb3alTXTk31YsWluLiYG264gT179lBWVkZWVlad+yJNgxYPjL9YH8JSNa56/qU2CRtJMbPmwPPAD4E+wHgz61Ol2o+Bk+7+PaAY+Hmi+hOt1mW76+HIkSNsD+9ZX7lyJfn5+fTq1YuSkhIOHjwIwPLlyykoKKi2vNz8+fNp164dM2bMiNlWWVlZxV0zr7/+Ovn5+THrDR8+nOeee65if/fu3QAMGzaMFStWALBhwwZOnjzZoHYGDx7MqlWrAFixYkWlemvWrKGsrIxDhw5x+PBhevbsyenTp+nUqRPNmjVj+fLlXLp0KeZxJTMMatOGud266Q0qTtJtdELPv9QkkSMpA4GD7n4YwMxWAaOB6LH90cBPw+1fAc+ZmXkjLCgU7+mce/fuzbJly5g2bRo5OTk8/PDDZGVlsXTpUsaNG0ckEiEvL4/p06fTokWLmOXRnnnmGaZMmcKcOXN46qmnKj3WqlUr9u/fz4ABA2jTpg2rV6+O2adnn32WRx55hL59+xKJRBg2bBiLFy/miSeeYPz48eTm5lJQUEDXrl1j/nxd2pkyZQpPP/00HTp0YOnSpRWP9ezZk4KCAo4ePcrixYvJyspixowZjBkzhjVr1nD77bfXOCojqen63bHf+E71u/pTp7dVc1fC21G3VNbWztX0o7Z2rqYftYnH73I1x7ja36Vn586czs6mTUkJc0tL63SMurSjYwR14vF3mCp/y6kmkUnKjcCfovZLgb+uro67R8zsNNAOqDRph5lNBaYC1b6hJlN2dna111UUFhaya9euqy4vKSmp2I5+s69qwYIFLFiwoFJZ1T/E9u3bx0ws2rVrx8aNGyv2i4uLG9ROdnY2W7ZsueJnX3311ZjHzMnJYe/evRX7CxcurLZ9Eam7NqWltCktTXY3RBosYasgm9k44G/d/cFw/35goLv/Q1Sd/WGd0nD/UFjnRHXH1SrIwa3BZ8+ebTLtiIhI5qppFeRE3t1TCnSJ2u8MfF5dHTO7BmgD/DmBfWoSGitxUIIiIiLJlMgkZQeQY2bdzexa4F5gXZU664CicHsssKUxrkcRERGR1Jewa1LCa0xmAr8luAX5FXffb2bzgQ/dfR3wMrDczA4SjKDcm6j+iIiISHpJ6Dwp7v5r4NdVyv41avs8MC6RfRAREZH0lJEzzoqIiEjqU5IiIiIiKUlJioiIiKQkJSkiIiKSkhI2mVuimNlx4LMGHKI9VWa0lQZTTONPMU0MxTX+FNP4y7SYdnP3DrEeSLskpaHM7MPqZraT+lFM408xTQzFNf4U0/hTTC/T6R4RERFJSUpSREREJCVlYpLyUrI70AQppvGnmCaG4hp/imn8KaahjLsmRURERNJDJo6kiIiISBpQkiIiIiIpKWOSFDMbYWYHzOygmf0k2f1JV2b2ipkdM7OPosq+a2abzOx/w+9tk9nHdGNmXczsd2b2iZntN7NZYbniWk9mlmVmH5jZnjCm88Ly7mb2fhjT1WZ2bbL7mm7MrLmZ7TKz9eG+YtpAZlZiZvvMbLeZfRiW6fVPhiQpZtYceB74IdAHGG9mfZLbq7T1KjCiStlPgM3ungNsDvfl6kWA2e7eG/g+8Ej496m41t8F4A53vxXoB4wws+8DPweKw5ieBH6cxD6mq1nAJ1H7iml83O7u/aLmR9HrnwxJUoCBwEF3P+zu3wKrgNFJ7lNacvdtwJ+rFI8GloXby4C/b9ROpTl3/8Ldd4bbXxG8AdyI4lpvHjgb7n4n/HLgDuBXYbliWkdm1hkYCfwi3DcU00TR65/MSVJuBP4UtV8alkl83ODuX0Dwhgt0THJ/0paZZQP9gfdRXBskPC2xGzgGbAIOAafcPRJW0f+BunsGmAOUhfvtUEzjwYGNZvYHM5salun1D1yT7A40EotRpnuvJaWY2XXAWuAf3f1M8CFV6svdLwH9zOx64A2gd6xqjdur9GVmdwLH3P0PZnZbeXGMqopp3Q1x98/NrCOwycw+TXaHUkWmjKSUAl2i9jsDnyepL03RUTPrBBB+P5bk/qQdM/sOQYKywt3/KyxWXOPA3U8BbxNc73O9mZV/ONP/gboZAowysxKCU+Z3EIysKKYN5O6fh9+PESTUA9HrH8icJGUHkBNehX4tcC+wLsl9akrWAUXhdhHwP0nsS9oJz+u/DHzi7v8R9ZDiWk9m1iEcQcHMWgI/ILjW53fA2LCaYloH7j7X3Tu7ezbB/9At7n4fimmDmFkrM/uL8m1gOPARev0DGTTjrJn9HUHW3xx4xd2fTHKX0pKZrQRuI1hK/CjwBPDfwC+BrsARYJy7V724VqphZvnA74F9XD7X/zjBdSmKaz2YWV+Ciw2bE3wY+6W7zzezmwhGAb4L7AImuvuF5PU0PYWne/7J3e9UTBsmjN8b4e41wOvu/qSZtUOv/8xJUkRERCS9ZMrpHhEREUkzSlJEREQkJSlJERERkZSkJEVERERSkpIUERERSUlKUkTkCmZ2KVyRdY+Z7TSzwfU8zm3lq+XWUsfN7K6osvVRs5o2SLjCbPt4HEtEGpeSFBGJ5Vy4IuutwFxgYYLbKwX+JcFt1FnUTKoikgRKUkSkNq2BkxDMjmtmT5vZR2a2z8zuqak8mpnlmdmucPKqqvYAp83sb2L8XMVIiJn9lZm9HW7/1MyWmdnGsM6PzOypsP3fhEsNlPtnM/sg/Ppe+PMdzGytme0Iv4ZEHfclM9sIvNaQwIlIw+hTgojE0jJcQTgL6ESwTgvAj4B+wK0Esw7vMLNtwOBqygEITxf9JzDa3Y9U0+a/hV+b6tDPvwRuB/oA24Ex7j7HzN4ARhLMhgxwxt0Hmtkkgpmn7wQWAcXu/o6ZdQV+y+VFCAcA+e5+rg59EZE4U5IiIrGcc/d+AGY2CHjNzG4G8oGV4QrDR81sK5BXQ/kZgjf+l4Dh5QupxeLuvzczzGxoHfq5wd0vmtk+ginwfxOW7wOyo+qtjPpeHG7/AOgTtdp06/I1VIB1SlBEkk9JiojUyN23h6dbOgBWTbXqygG+IBiR6U/tK+Q+SXBtSiSqLMLlU9NZVepfCPtYZmYX/fI6H2VU/v/mMbabAYOqJiNh0vJ1Lf0UkUaga1JEpEZm1otglOIEsA24x8yam1kHYBjwQQ3lAKcITr38e2137Lj7RqAtwWmjciUEp18AxtTz17gn6vv2cHsjMLO8gpn1q+exRSRBNJIiIrGUX5MCwShJkbtfCq/1GERwoasDc9z9/2oo7wXg7kfDW4w3mNkUd3+/hrafpPKy9POAl82sfGXo+mhhZu8TfDAbH5Y9CjxvZnsJ/hduA6bX8/gikgBaBVlERERSkk73iIiISEpSkiIiIiIpSUmKiIiIpCQlKSIiIpKSlKSIiIhISlKSIiIiIilJSYqIiIikpP8HqO6qoGZ4f9wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "plt.axhline(.5,c='#555555')\n",
    "plt.scatter(range(1,55),results['authenticity'],\n",
    "            c='k', marker='_')\n",
    "plt.scatter(bads, results.loc[results['book'].map(lambda b: b in bads),\n",
    "                              'authenticity'],\n",
    "            c='lime', marker='_', alpha=1)\n",
    "plt.scatter(range(1,55),results['w2vsvm chap pred avg'],\n",
    "            c='r', marker='.')\n",
    "plt.scatter(range(1,55),results['w2vsvm chap pred proba avg'],\n",
    "            c='pink', marker='.')\n",
    "plt.scatter(range(1,55),results['w2vsvm book pred proba'], \n",
    "            c='c', marker='.')\n",
    "plt.legend(['50%','true authenticity', 'a method mispredicted this book',\n",
    "            'chap pred avg','chap pred proba avg','book pred proba'],\n",
    "           fancybox=True, framealpha=0)\n",
    "plt.title('Predicted Animorphs Book Authenticity Probabilities')\n",
    "plt.xlabel('Book Number')\n",
    "plt.ylabel('Authenticity Probability')\n",
    "plt.savefig('../figures/first_results.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot contains a lot of information; it shows predicted authenticity probabilities for each W2V-based SVM for each Animorphs book. Ideally there would be no appearance of a linear relationship here, but because the books were written sequentially, it makes sense for one to have a small presence. \n",
    "\n",
    "However, especially for averaged chapter-based predictions, there seems to be a consistent and notable linear decline in probability over increasing book number. Notably, the books most often inaccurately predicted are those 'out of place' in order, early ghostwritten books and authentic books surrounded by ghostwritten books. We believe that this is a sign of a flaw in the model, that it registers a shift in content more than any shift in author's style. This would mean that the Word2Vec word embedding is inappropriate for stylometry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midway Reassessment\n",
    "\n",
    "Though word embedding's appropriateness for stylometry is disputed, [these](https://pdfs.semanticscholar.org/3fd9/c3a45629393465e7258dee0f1eaab32ea4bc.pdf) [papers](https://www.aclweb.org/anthology/Q15-1016.pdf), suggest that it is especially poorly-suited to authorship analysis, as it obscures the author specific quality of word choice for a more general, content-based view of text. \n",
    "\n",
    "Because Word2Vec analysis seems unfruitful, we treat this transfer learning model as our baseline and attempt some more traditional stylometric analyses that are clearly geared toward style rather than content. Where these methods abstracted words and texts to vectors, we will instead model off of straightforward word (and punctuation) counts to discern authenticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Continue to next notebook.](./04_classifiers_on_words.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
